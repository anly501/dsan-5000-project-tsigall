{"title":"Dimensionality Reduction","markdown":{"yaml":{"title":"Dimensionality Reduction","bibliography":"reference.bib"},"headingText":"Principal Component Analysis","containsRefs":false,"markdown":"\n\n```{r setup, include = FALSE}\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(reticulate)\nlibrary(gridExtra)\nknitr::opts_chunk$set(echo = FALSE)\n```\n\n```{r include = FALSE}\nload(\"raw_nfl.Rdata\")\n```\n\n\n```{r}\ndf <- raw_data %>%\n    filter(!is.na(go_boost) & !is.na(go)) %>%\n    select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)\ndf <- df %>%\n  mutate(coach = if_else(posteam_type == \"home\", home_coach, away_coach),\n         home_coach = coach,\n         score_diff = posteam_score - defteam_score,\n         go = if_else(go == 100, 1, 0),\n         game_half = if_else(game_half == \"Half1\", 1, 2)) %>%\n  select(-coach,\n         -away_coach,\n         -season,\n         -posteam,\n         -defteam,\n         -posteam_type,\n         -epa,\n         -punt_wp,\n         -posteam_score,\n         -defteam_score) %>%\n  rename(coach = home_coach) %>%\n  select(-go, everything())\n\nwrite.csv(df, \"df.csv\")\n```\n\n```{python echo = TRUE}\nimport json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n```\n\n```{python, echo = TRUE}\nX = r.df\nto_drop = [\"coach\", \"go\"]\nX = X.drop(to_drop, axis = 1)\nY = r.df[\"go\"]\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\npca = PCA(n_components = 5).fit(X)\nvariance_ratios = pca.explained_variance_ratio_\n```\n\n```{python}\nplt.cla()\nplt.plot(range(1, len(variance_ratios) + 1), variance_ratios, marker='o')\nplt.xlabel(\"Principal Component\")\nplt.ylabel(\"Prop. Variance Explained\")\nplt.show()\n```\n\nThe optimal number of principal components to keep is 2, looking at where the \"elbow\" is on this graph of the proporition variance explained by each principal component.\n\n```{python}\npca = PCA(n_components =  2).fit(X)\nXp = pca.transform(X)\nXp_df = pd.DataFrame(Xp, columns = ['x', 'y'])\n```\n\n```{r}\nggplot(data = py$Xp_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"First Principal Component\", y = \"Second Principal Component\") +\n  geom_abline(intercept = 1, slope = 0.3, color = \"black\", linewidth = 1.5) + \n  theme_minimal()\n```\n\nWhen graphing the first and second principal components and coloring each based on whether the coach attempted a conversion on the play (0 being no and 1 being yes), we can see some clustering take place. There is a clear main group of points with most of the green points being in the upper left portion of the cluster, and the red points being in the bottom right. There are more red than green points, which makes sense as there are more 4th down plays where coaches did not go for it than ones where they did. There are also some outliers where points increase in the y-direction up to 8. From this analysis, it is worth looking at those outliers to see why they are so far up there, as well as the points that are on the edge of the border between red and green points. I have drawn an approximate line on the graph for demonstration purposes, just to show the area that I think is worth looking at.\n\n# t-SNE\n\n```{python echo = TRUE}\nfrom sklearn.manifold import TSNE\n```\n\n```{python}\n# X_5 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=5, n_iter=300).fit_transform(X)\n# X5_df = pd.DataFrame(X_5, columns = ['x', 'y'])\n# \n# X_10 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=10, n_iter=300).fit_transform(X)\n# X10_df = pd.DataFrame(X_10, columns = ['x', 'y'])\n# \n# X_20 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=20, n_iter=300).fit_transform(X)\n# X20_df = pd.DataFrame(X_20, columns = ['x', 'y'])\n# \n# X_30 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=30, n_iter=300).fit_transform(X)\n# X30_df = pd.DataFrame(X_30, columns = ['x', 'y'])\n# \n# X_40 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=40, n_iter=300).fit_transform(X)\n# X40_df = pd.DataFrame(X_40, columns = ['x', 'y'])\n# \n# X_50 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=50, n_iter=300).fit_transform(X)\n# X50_df = pd.DataFrame(X_50, columns = ['x', 'y'])\n```\n\n```{r}\nload(\"tsne.Rdata\")\n```\n\n```{r}\np5 <- ggplot(data = X5, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 5\")\n\np10 <- ggplot(data = X10, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 10\")\n\np20 <- ggplot(data = X20, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 20\")\n\np30 <- ggplot(data = X30, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 30\")\n\np40 <- ggplot(data = X40, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 40\")\n\np50 <- ggplot(data = X50, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 50\")\n```\n\n::: panel-tabset\n## Perplexity = 5\n\n```{r}\np5\n```\n\n## Perplexity = 10\n\n```{r}\np10\n```\n\n## Perplexity = 20\n\n```{r}\np20\n```\n\n## Perplexity = 30\n\n```{r}\np30\n```\n\n## Perplexity = 40\n\n```{r}\np40\n```\n\n## Perplexity = 50\n\n```{r}\np50\n```\n:::\n\nPerplexity levels 20 and 30 seem to do the best job at reducing the dimensions so that similar points are grouped together, as there are clearer areas of green within the larger areas of red. However, going forward I would prefer to use PCA as my chosen method of dimensionality reduction due to the clearer distinction drawn between the two types of points. PCA seems to preserve data structure and information better than t-SNE because of this difference. The visualization capabilities are similar between the two, though it was easier to make a distinction between points in this case, as I only have two categories of points I am looking at. This may be a place that PCA outperforms t-SNE, as there are only two types of points. If there were multiple scenarios being looked at, then t-SNE may perform better. This is worth keeping in mind going forward as there are instances where there are many categories of points that could be looked at.\n","srcMarkdownNoYaml":"\n\n```{r setup, include = FALSE}\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(reticulate)\nlibrary(gridExtra)\nknitr::opts_chunk$set(echo = FALSE)\n```\n\n```{r include = FALSE}\nload(\"raw_nfl.Rdata\")\n```\n\n# Principal Component Analysis\n\n```{r}\ndf <- raw_data %>%\n    filter(!is.na(go_boost) & !is.na(go)) %>%\n    select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)\ndf <- df %>%\n  mutate(coach = if_else(posteam_type == \"home\", home_coach, away_coach),\n         home_coach = coach,\n         score_diff = posteam_score - defteam_score,\n         go = if_else(go == 100, 1, 0),\n         game_half = if_else(game_half == \"Half1\", 1, 2)) %>%\n  select(-coach,\n         -away_coach,\n         -season,\n         -posteam,\n         -defteam,\n         -posteam_type,\n         -epa,\n         -punt_wp,\n         -posteam_score,\n         -defteam_score) %>%\n  rename(coach = home_coach) %>%\n  select(-go, everything())\n\nwrite.csv(df, \"df.csv\")\n```\n\n```{python echo = TRUE}\nimport json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n```\n\n```{python, echo = TRUE}\nX = r.df\nto_drop = [\"coach\", \"go\"]\nX = X.drop(to_drop, axis = 1)\nY = r.df[\"go\"]\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\npca = PCA(n_components = 5).fit(X)\nvariance_ratios = pca.explained_variance_ratio_\n```\n\n```{python}\nplt.cla()\nplt.plot(range(1, len(variance_ratios) + 1), variance_ratios, marker='o')\nplt.xlabel(\"Principal Component\")\nplt.ylabel(\"Prop. Variance Explained\")\nplt.show()\n```\n\nThe optimal number of principal components to keep is 2, looking at where the \"elbow\" is on this graph of the proporition variance explained by each principal component.\n\n```{python}\npca = PCA(n_components =  2).fit(X)\nXp = pca.transform(X)\nXp_df = pd.DataFrame(Xp, columns = ['x', 'y'])\n```\n\n```{r}\nggplot(data = py$Xp_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"First Principal Component\", y = \"Second Principal Component\") +\n  geom_abline(intercept = 1, slope = 0.3, color = \"black\", linewidth = 1.5) + \n  theme_minimal()\n```\n\nWhen graphing the first and second principal components and coloring each based on whether the coach attempted a conversion on the play (0 being no and 1 being yes), we can see some clustering take place. There is a clear main group of points with most of the green points being in the upper left portion of the cluster, and the red points being in the bottom right. There are more red than green points, which makes sense as there are more 4th down plays where coaches did not go for it than ones where they did. There are also some outliers where points increase in the y-direction up to 8. From this analysis, it is worth looking at those outliers to see why they are so far up there, as well as the points that are on the edge of the border between red and green points. I have drawn an approximate line on the graph for demonstration purposes, just to show the area that I think is worth looking at.\n\n# t-SNE\n\n```{python echo = TRUE}\nfrom sklearn.manifold import TSNE\n```\n\n```{python}\n# X_5 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=5, n_iter=300).fit_transform(X)\n# X5_df = pd.DataFrame(X_5, columns = ['x', 'y'])\n# \n# X_10 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=10, n_iter=300).fit_transform(X)\n# X10_df = pd.DataFrame(X_10, columns = ['x', 'y'])\n# \n# X_20 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=20, n_iter=300).fit_transform(X)\n# X20_df = pd.DataFrame(X_20, columns = ['x', 'y'])\n# \n# X_30 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=30, n_iter=300).fit_transform(X)\n# X30_df = pd.DataFrame(X_30, columns = ['x', 'y'])\n# \n# X_40 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=40, n_iter=300).fit_transform(X)\n# X40_df = pd.DataFrame(X_40, columns = ['x', 'y'])\n# \n# X_50 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=50, n_iter=300).fit_transform(X)\n# X50_df = pd.DataFrame(X_50, columns = ['x', 'y'])\n```\n\n```{r}\nload(\"tsne.Rdata\")\n```\n\n```{r}\np5 <- ggplot(data = X5, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 5\")\n\np10 <- ggplot(data = X10, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 10\")\n\np20 <- ggplot(data = X20, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 20\")\n\np30 <- ggplot(data = X30, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 30\")\n\np40 <- ggplot(data = X40, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 40\")\n\np50 <- ggplot(data = X50, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 50\")\n```\n\n::: panel-tabset\n## Perplexity = 5\n\n```{r}\np5\n```\n\n## Perplexity = 10\n\n```{r}\np10\n```\n\n## Perplexity = 20\n\n```{r}\np20\n```\n\n## Perplexity = 30\n\n```{r}\np30\n```\n\n## Perplexity = 40\n\n```{r}\np40\n```\n\n## Perplexity = 50\n\n```{r}\np50\n```\n:::\n\nPerplexity levels 20 and 30 seem to do the best job at reducing the dimensions so that similar points are grouped together, as there are clearer areas of green within the larger areas of red. However, going forward I would prefer to use PCA as my chosen method of dimensionality reduction due to the clearer distinction drawn between the two types of points. PCA seems to preserve data structure and information better than t-SNE because of this difference. The visualization capabilities are similar between the two, though it was easier to make a distinction between points in this case, as I only have two categories of points I am looking at. This may be a place that PCA outperforms t-SNE, as there are only two types of points. If there were multiple scenarios being looked at, then t-SNE may perform better. This is worth keeping in mind going forward as there are instances where there are many categories of points that could be looked at.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"dimensionality_reduction.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","theme":"sandstone","fontsize":"1em","title":"Dimensionality Reduction","bibliography":["reference.bib"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}