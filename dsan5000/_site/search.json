[
  {
    "objectID": "naive_bayes.html",
    "href": "naive_bayes.html",
    "title": "Naïve Bayes Introduction",
    "section": "",
    "text": "Naïve Bayes methods are a set of supervised learning algorithms based on combining Bayes’ theorem with the assumption that the features used in the classification algorithm are conditionally independent. This is the naïve assumption. Essentially, it assumes that the presence of one feature does not affect the presence of the other features. The other component of these methods are that they are based on Bayes’ theorem which describes the probability of an event based on prior knowledge of that event. This probability is constantly updating, and is represented in the formula in this case as \\[P(y|x_1,...,x_n) = \\frac{(P(y)P(x_1,...x_n|y)}{P(x_1,...,x_n)}\\]\nPutting this in the context of a classification problem, we want to determine the likelihood that an event belongs to class \\(y\\) given the features we select from the data, those being \\(x_1,...x_n\\). To do this, labelled training data is needed. Each algorithm will estimate prior probabilities \\(P(y)\\) for each class and likelihood probabilities for each feature \\(P(x_1,...x_n|y)\\) from this training data. Then, a posterior probability for each class \\(P(y|x_1,...x_n)\\) is calculated and the highest probability is determined to be the class for the data.\nThere are several types of Naïve Bayes algorithms, those being Gaussian, Multinomial, and Bernoulli Naïve Bayes. Gaussian is used when continuous, normally distributed data is obtained. In this case, the likelihood of features is assumed to be normally distributed. \\(\\sigma_y\\) and \\(\\mu_y\\) are estimated using maximum likelihood as in the steps outlined above. Multinomial is used for multinomially distributed data and commonly used in text classification with data in the form of vectors representing word counts. \\(\\theta_y\\) is estimated in this case where \\(\\theta_{yi}\\) is the probability \\(P(x_i|y)\\) of feature \\(i\\) appearing in a sample of class \\(y\\). Finally, Bernoulli is used when there are multiple features but each one is binary.\nIn this case we will be using Gaussian Naïve Bayes, as we have continuous data that we would like to predict."
  },
  {
    "objectID": "coach_clustering.html",
    "href": "coach_clustering.html",
    "title": "Clustering",
    "section": "",
    "text": "Attempting to “profile” each coach by how they perform on 4th down may give us some important insights into how they make their decisions. This would be a good fit for an unsupervised learning task, as this is just some exploratory analysis to see if we can extract some trends from this data. We do not know yet what kinds of coaches there may be out there, so lets attempt to group them based on the data we do have."
  },
  {
    "objectID": "coach_clustering.html#k-means",
    "href": "coach_clustering.html#k-means",
    "title": "Clustering",
    "section": "K-Means",
    "text": "K-Means\nK-Means clustering is a centroid based clustering algorithm that aims to categorize each observation into the nearest cluster out of the total number k. To do this it randomly picks k points, then computes the distance from each point to each observation. Each observation is assigned the centroid it is closest to, then the centroids are recalculated based on these assignments and the process repeats. This repeats until it is stationary."
  },
  {
    "objectID": "coach_clustering.html#dbscan",
    "href": "coach_clustering.html#dbscan",
    "title": "Clustering",
    "section": "DBSCAN",
    "text": "DBSCAN\nDBSCAN is a density based clustering algorithm that groups points together based on how close they are to their neighbors. Core points are determined, those being ones that have a certain amount of points close by. Other observations are assigned to the same cluster as those core points if they are within a certain distance of that point. The process repeats until stationary. As a result, outliers belong their own clusters as they are not close to any other points."
  },
  {
    "objectID": "coach_clustering.html#agglomerative",
    "href": "coach_clustering.html#agglomerative",
    "title": "Clustering",
    "section": "Agglomerative",
    "text": "Agglomerative\nAgglomerative clustering is a hierarchical clustering algorithm that initially treats each point as its own cluster. The distance between each observation is calculated, and the two closest points are determined to be a cluster. They are merged and the distance matrix is updated with one less cluster (as two clusters (points) were just merged). The two closest clusters are then determined and merged, and this repeats until some stopping criterion is met."
  },
  {
    "objectID": "coach_clustering.html#clean-data-for-clustering",
    "href": "coach_clustering.html#clean-data-for-clustering",
    "title": "Clustering",
    "section": "Clean Data for Clustering",
    "text": "Clean Data for Clustering\nWe want to select the features to be used during this process, lets try just using two features to start with: should_go and shouldnt_go from our earlier cleaning process. Lets also group by coach alone and not by coach and season to make it easier to interpret the final output.\n\n\nCode\nload(\"data/clean_data.Rdata\")\n\nfourth_by_coach &lt;- fourth_decisions %&gt;% \n  group_by(coach) %&gt;%\n  summarize(should_go = mean(should_go),\n            shouldnt_go = mean(shouldnt_go)) %&gt;%\n  ungroup()\n  \nhead(fourth_by_coach)\n\n\n# A tibble: 6 × 3\n  coach          should_go shouldnt_go\n  &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt;\n1 Adam Gase          0.248       0.957\n2 Andy Reid          0.295       0.979\n3 Anthony Lynn       0.272       0.955\n4 Arthur Smith       0.358       0.963\n5 Ben McAdoo         0.267       0.977\n6 Bill Belichick     0.238       0.965\n\n\nLets get an initial look at the data before applying the clustering algorithm.\n\n\nCode\nplot_ly(data = fourth_by_coach, x = ~should_go, y = ~shouldnt_go, type = \"scatter\", mode = \"markers\")\n\n\n\n\n\n\nObvious clusters have not formed from this, but we will still proceed with the unsupervised learning task.\n\nSetup\n\n\nPython Imports\nimport pandas as pd\nimport numpy as np\nfrom sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nimport sklearn\n\nnp.random.seed(621)\n\n\n\n\nRead Data\ndf = pd.read_csv(\"data/fourth_by_coach.csv\")\nscaler = StandardScaler()\nX = scaler.fit_transform(df[[\"should_go\", \"shouldnt_go\"]])\n\n\n\n\nPlotting Function\n# plotting function from lab 4.1 demo\ndef plot(X,color_vector):\n    fig, ax = plt.subplots()\n    ax.scatter(X[:,0], X[:,1],c=color_vector, alpha=0.5) #, c=y\n    ax.set(xlabel='Feature-1 (x_1)', ylabel='Feature-2 (x_2)',\n    title='Cluster data')\n    ax.grid()\n    # fig.savefig(\"test.png\")\n    plt.show()"
  },
  {
    "objectID": "coach_clustering.html#k-means-1",
    "href": "coach_clustering.html#k-means-1",
    "title": "Clustering",
    "section": "K-Means",
    "text": "K-Means\n\n\nCode\nX = np.ascontiguousarray(X)\nk_means_X = pd.DataFrame(columns = [\"Cluster\", \"Inertia\"], index = range(10))\n\nfor i in range(1,11):\n  model = KMeans(n_clusters = i, n_init = 10).fit(X)\n  k_means_X.at[i - 1, \"Inertia\"] = model.inertia_\n  k_means_X.at[i - 1, \"Cluster\"] = i\n  \n\nplt.clf()\nsns.lineplot(data = k_means_X, x = \"Cluster\", y = \"Inertia\")\nplt.show()\n\n\n\n\n\nUsing the elbow method, the correct number of clusters here seems to be about 3, we will try 2, 3, and 4.\n\n2 Clusters3 Clusters4 Clusters\n\n\n\n\nCode\nlabels = KMeans(n_clusters = 2, n_init = 10).fit(X).labels_\n\nplot(X, labels)\n\n\n\n\n\n\n\n\n\nCode\nlabels = KMeans(n_clusters = 3, n_init = 10).fit(X).labels_\n\nplot(X, labels)\n\n\n\n\n\n\n\n\n\nCode\nnp.random.seed(621)\nlabels = KMeans(n_clusters = 4, n_init = 10).fit(X).labels_\n\nplot(X, labels)\n\n\n\n\n\n\n\n\nI like 4 clusters the best as we are looking at 2 features here, we can form “quadrants” of sorts. Lets apply the labels to the points and see which coaches fell into which categories."
  },
  {
    "objectID": "coach_clustering.html#dbscan-1",
    "href": "coach_clustering.html#dbscan-1",
    "title": "Clustering",
    "section": "DBSCAN",
    "text": "DBSCAN\n\n\nCode\nDBSCAN_X = pd.DataFrame(columns = [\"eps\", \"Silhouette\"], index = range(10))\n\nfor i in range(1,12):\n  eps = 0.2*i\n  model = DBSCAN(eps=eps).fit(X)\n  labels = model.labels_\n  try:\n    DBSCAN_X.at[i - 1, \"Silhouette\"] = sklearn.metrics.silhouette_score(X,labels)\n  except:\n    continue\n  DBSCAN_X.at[i - 1, \"eps\"] = eps\n  \n\nplt.clf()\nsns.lineplot(data = DBSCAN_X, x = \"eps\", y = \"Silhouette\")\nplt.show()\n\n\n\n\n\nIt looks like the silhouette score is best when the eps is 1.2. Past that there is little to no increase.\n\neps = 0.8eps = 1.0eps = 1.2\n\n\n\n\nCode\nnp.random.seed(621)\nlabels = DBSCAN(eps = 0.8).fit(X).labels_\n\nplot(X, labels)\n\n\n\n\n\n\n\n\n\nCode\nnp.random.seed(621)\nlabels = DBSCAN(eps = 1.0).fit(X).labels_\n\nplot(X, labels)\n\n\n\n\n\n\n\n\n\nCode\nnp.random.seed(621)\nlabels = DBSCAN(eps = 1.2).fit(X).labels_\n\nplot(X, labels)"
  },
  {
    "objectID": "coach_clustering.html#agglomerative-1",
    "href": "coach_clustering.html#agglomerative-1",
    "title": "Clustering",
    "section": "Agglomerative",
    "text": "Agglomerative\n\n\nCode\nagg_X = pd.DataFrame(columns = [\"Clusters\", \"Silhouette\"], index = range(15))\n\nfor i in range(1,16):\n  model = AgglomerativeClustering(n_clusters=i).fit(X)\n  labels = model.labels_\n  try:\n    agg_X.at[i - 1, \"Silhouette\"] = sklearn.metrics.silhouette_score(X,labels)\n  except:\n    continue\n  agg_X.at[i - 1, \"Clusters\"] = i\n  \n\nplt.clf()\nsns.lineplot(data = agg_X, x = \"Clusters\", y = \"Silhouette\")\nplt.show()\n\n\n\n\n\nThe best number of clusters looks to be around 8, we will try 4, 8, and 12.\n\n4 Clusters8 Clusters12 Clusters\n\n\n\n\nCode\nlabels = AgglomerativeClustering(n_clusters = 4).fit(X).labels_\n\nplot(X, labels)\n\n\n\n\n\n\n\n\n\nCode\nlabels = AgglomerativeClustering(n_clusters = 8).fit(X).labels_\n\nplot(X, labels)\n\n\n\n\n\n\n\n\n\nCode\nnp.random.seed(621)\nlabels = AgglomerativeClustering(n_clusters = 12).fit(X).labels_\n\nplot(X, labels)\n\n\n\n\n\n\n\n\n8 and 12 seem to be too many clusters, and 4 looks very similar to the result from K-Means clustering so we will continue using that result."
  },
  {
    "objectID": "data_cleaning3.html",
    "href": "data_cleaning3.html",
    "title": "Decision Trees Cleaning",
    "section": "",
    "text": "Inputs\nlibrary(tidyverse)\nlibrary(kableExtra)\n\n\n\nDecision Trees\nFor our decision tree building, we would like to format our play by play data in a slightly different manner. Mainly, we want to only have the coach of the team on offense as we are evaluating their deicion-making, not the defensive team’s coach. Also, we want to drop unnecessary columns and make a singular score_diff column, rather than have separate columns for posteam_score and defteam_score. The resultant table can be seen below, and is used in our decision tree analysis later on in the project.\n\n\nCode\nload(\"data/raw_nfl.Rdata\")\ndf &lt;- raw_data %&gt;%\n    filter(!is.na(go_boost) & !is.na(go)) %&gt;%\n    select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)\ndf &lt;- df %&gt;%\n  mutate(coach = if_else(posteam_type == \"home\", home_coach, away_coach),\n         home_coach = coach,\n         score_diff = posteam_score - defteam_score,\n         go = if_else(go == 100, 1, 0),\n         game_half = if_else(game_half == \"Half1\", 1, 2)) %&gt;%\n  select(-coach,\n         -away_coach,\n         -season,\n         -posteam,\n         -defteam,\n         -posteam_type,\n         -epa,\n         -punt_wp,\n         -posteam_score,\n         -defteam_score) %&gt;%\n  rename(coach = home_coach) %&gt;%\n  select(-go, everything())\nwrite.csv(df, \"data/dt.csv\")\n\nkable(head(df))\n\n\n\n\n\ncoach\ngame_half\nhalf_seconds_remaining\nydstogo\nyardline_100\ngo_boost\nwp_fail\nwp_succeed\nwp\nfg_make_prob\nmiss_fg_wp\nmake_fg_wp\nscore_diff\ngo\n\n\n\n\nJohn Harbaugh\n1\n1625\n1\n66\n1.8427797\n0.4501592\n0.5882827\n0.5102725\n0.0000000\n0.4320890\n0.5741632\n0\n0\n\n\nJohn Harbaugh\n1\n1612\n6\n71\n-1.1323169\n0.4403515\n0.5971214\n0.4710029\n0.0000000\n0.4196399\n0.5725211\n0\n0\n\n\nRex Ryan\n1\n1482\n18\n76\n-5.7820437\n0.3423280\n0.5154754\n0.4189611\n0.0000000\n0.3280475\n0.5250292\n0\n0\n\n\nRex Ryan\n1\n1230\n6\n43\n2.0073829\n0.3919702\n0.5667855\n0.4749633\n0.0000000\n0.3907058\n0.5210628\n0\n0\n\n\nRex Ryan\n1\n1230\n11\n48\n-0.6287521\n0.3906138\n0.5670854\n0.4759269\n0.0000000\n0.3771124\n0.5210628\n0\n0\n\n\nJohn Harbaugh\n1\n941\n15\n32\n-4.0096273\n0.5135549\n0.6866364\n0.5298005\n0.6625606\n0.4986032\n0.6224666\n0\n0"
  },
  {
    "objectID": "random_forests.html",
    "href": "random_forests.html",
    "title": "Random Forests",
    "section": "",
    "text": "Here we will follow a similar process as seen in the Decision Trees tab, but instead creating a Random Forest model to see if that results in better performance. The explanation of this process will be less detailed here as the inital setup is very similar to the process seen in the decision trees tab, for a more in depth explanation of the setup that tab.\n\n\nImports\nimport pandas as pd\nimport seaborn as sns \nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\n\n\n\nImport Data\n\n\nImports Data and Train/Test Split\ndf = pd.read_csv(\"data/df.csv\").drop([\"coach\", \"posteam_score\", \"defteam_score\"], axis=1)\npd.set_option('display.float_format', '{:.2f}'.format)\n\nX = df.loc[:,[\"game_half\", \"half_seconds_remaining\", \"ydstogo\", \"yardline_100\", \"score_diff\"]]\nY = df[\"go\"]\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=621)\n\n# Check size of train and test splits\nprint(\"x_train shape:\", x_train.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"x_test shape:\", x_test.shape)\nprint(\"y_test shape:\", y_test.shape)\n\n\nx_train shape: (22315, 5)\ny_train shape: (22315,)\nx_test shape: (5579, 5)\ny_test shape: (5579,)\n\n\n\n\nTraining the Model\n\nclf = RandomForestClassifier(n_estimators=100, random_state=621)\nmodel = clf.fit(x_train.values, y_train)\n\nFor now we will have a n_estimators parameter of 100, though that hyperparameter will be tuned later.\n\n\nCheck the Model\n\n\nGenerate Confusion Matrices\nyp_train = model.predict(x_train.values)\nyp_test = model.predict(x_test.values)\n\ndef confusion_plot(y_data, y_pred):\n    cm = confusion_matrix(y_data, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                                  display_labels=model.classes_)\n    print(\"ACCURACY: \", round(accuracy_score(y_data, y_pred), 3))\n    print(\"NEGATIVE RECALL (Y=0): \", round(recall_score(y_data, y_pred, pos_label=0), 3))\n    print(\"NEGATIVE PRECISION (Y=0): \", round(precision_score(y_data, y_pred, pos_label=0), 3))\n    print(\"POSITIVE RECALL (Y=1): \", round(recall_score(y_data, y_pred, pos_label=1), 3))\n    print(\"POSITIVE PRECISION (Y=1): \", round(precision_score(y_data, y_pred, pos_label=1), 3))\n    print(cm)\n    disp.plot()\n    plt.show()\n    \n# print(\"------TRAINING------\")\n# confusion_plot(y_train,yp_train)\n\nprint(\"------TEST------\")\nconfusion_plot(y_test,yp_test)\n\n\n------TEST------\nACCURACY:  0.912\nNEGATIVE RECALL (Y=0):  0.961\nNEGATIVE PRECISION (Y=0):  0.935\nPOSITIVE RECALL (Y=1):  0.659\nPOSITIVE PRECISION (Y=1):  0.77\n[[4483  180]\n [ 312  604]]\n\n\n\n\n\nNegative recall and precision are very good, meaning our model is good at predicting when coaches will not go for it, which makes sense. Positive recall and precision, on the other hand, are not nearly as good. It is much harder to predict when coaches will go for it than when they will not go for it. This model is slightly better than our decision tree so far, though we have yet to tune the model.\n\n\nHyperparameter Tuning\n\n\nn_estimators Tuning\ntest_results=[]\ntrain_results=[]\n\nfor n_estimators in range(100, 1000, 100):\n    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=621)\n    model = clf.fit(x_train, y_train)\n\n    yp_train=model.predict(x_train)\n    yp_test=model.predict(x_test)\n\n    # print(y_pred.shape)\n    test_results.append([n_estimators,\n    accuracy_score(y_test, yp_test),\n    recall_score(y_test, yp_test,pos_label=0),\n    recall_score(y_test, yp_test,pos_label=1)])\n    \n    train_results.append([n_estimators,\n    accuracy_score(y_train, yp_train),\n    recall_score(y_train, yp_train,pos_label=0),\n    recall_score(y_train, yp_train,pos_label=1)])\n\n\n\n\nn_estimators Plots\nplt.cla()\nax = sns.lineplot(x=np.asarray(test_results)[:,0],\n                y=np.asarray(test_results)[:,1],\n                color=\"red\",\n                marker=\"o\",\n                label=\"test\")\nax.set(xlabel=\"Number of trees in forest (n_estimators)\", ylabel=\"ACCURACY\")\nplt.legend()\nplt.show()\n\nplt.cla()\nax = sns.lineplot(x=np.asarray(test_results)[:,0],\n                y=np.asarray(test_results)[:,3],\n                color=\"red\",\n                marker=\"o\",\n                label=\"test\")\nax.set(xlabel=\"Number of trees in forest (n_estimators)\", ylabel=\"POSITIVE RECALL (Y=1)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n200 appears to be the optimal n_estimators parameter, we will fit a model with that value. Note also that the accuracy at that level of estimators is over 91%, meaning we have an excellent model.\nOptimized forest metrics:\n\n\nCode\nclf = RandomForestClassifier(n_estimators=200, random_state=621)\nmodel = clf.fit(x_train.values, y_train)\n\nyp_train = model.predict(x_train.values)\nyp_test = model.predict(x_test.values)\n\nconfusion_plot(y_test, yp_test)\n\n\nACCURACY:  0.912\nNEGATIVE RECALL (Y=0):  0.961\nNEGATIVE PRECISION (Y=0):  0.935\nPOSITIVE RECALL (Y=1):  0.662\nPOSITIVE PRECISION (Y=1):  0.771\n[[4483  180]\n [ 310  606]]\n\n\n\n\n\n\n\nFeature Importance\nAs it is difficult to visualize the trees in a random forest due to their compelxity, we can visualize the importance of each of the features, allowing us to compare this model to the previous decision tree model.\n\n\nFeature Importance\nfrom yellowbrick.model_selection import FeatureImportances\n\n# Visualize feature importances\nviz = FeatureImportances(model)\nviz.fit(x_train, y_train)\nviz.show()\n\n\n\n\n\n&lt;Axes: title={'center': 'Feature Importances of 5 Features using RandomForestClassifier'}, xlabel='relative importance'&gt;\n\n\nA difference we can see here is that all features are considered important, which makes sense due to the complexity of this model. game_half is clearly the least important features, with all others being of similar importance. Making this type of graph for each individual coach would give us important insights into their decision making processes, as we can see what game state characteristics they value more than others. This plot is, in a way, a baseline metric by which to compare all other coaches to. Since this model was fitted with data from every coach, it can be considered what the “average” NFL coach considered when making a 4th down decision. If the order of features is different for another coach, they approach 4th downs differently than the average coach, something that will be interesting to see."
  },
  {
    "objectID": "feature_record.html",
    "href": "feature_record.html",
    "title": "Record Data",
    "section": "",
    "text": "Imports\nlibrary(tidyverse)\nlibrary(kableExtra)"
  },
  {
    "objectID": "feature_record.html#prepare-data",
    "href": "feature_record.html#prepare-data",
    "title": "Record Data",
    "section": "Prepare Data",
    "text": "Prepare Data\n\n\n\n\n\ncoach\ngame_half\nhalf_seconds_remaining\nydstogo\nyardline_100\nposteam_score\ndefteam_score\ngo_boost\nwp_fail\nwp_succeed\nwp\nfg_make_prob\nmiss_fg_wp\nmake_fg_wp\npunt_wp\nscore_diff\ngo\n\n\n\n\nJohn Harbaugh\n1\n1625\n1\n66\n0\n0\n1.8427797\n0.4501592\n0.5882827\n0.5102725\n0.0000000\n0.4320890\n0.5741632\n0.5265389\n0\n0\n\n\nJohn Harbaugh\n1\n1612\n6\n71\n0\n0\n-1.1323169\n0.4403515\n0.5971214\n0.4710029\n0.0000000\n0.4196399\n0.5725211\n0.5166918\n0\n0\n\n\nRex Ryan\n1\n1482\n18\n76\n0\n0\n-5.7820437\n0.3423280\n0.5154754\n0.4189611\n0.0000000\n0.3280475\n0.5250292\n0.4171238\n0\n0\n\n\nRex Ryan\n1\n1230\n6\n43\n0\n0\n2.0073829\n0.3919702\n0.5667855\n0.4749633\n0.0000000\n0.3907058\n0.5210628\n0.4426614\n0\n0\n\n\nRex Ryan\n1\n1230\n11\n48\n0\n0\n-0.6287521\n0.3906138\n0.5670854\n0.4759269\n0.0000000\n0.3771124\n0.5210628\n0.4410649\n0\n0\n\n\nJohn Harbaugh\n1\n941\n15\n32\n0\n0\n-4.0096273\n0.5135549\n0.6866364\n0.5298005\n0.6625606\n0.4986032\n0.6224666\n0.5387274\n0\n0\n\n\n\n\n\n\n\nFeatures for this model include: game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, go_boost, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp.\nWe want to look at the decision making process of each individual coach. To start, lets look at the process of the coach that has stayed on the same team and had the most 4th down situations over the past 8 NFL seasons: Bill Belichick.\n\n\nCode\nkable(head(df %&gt;%\n  group_by(coach) %&gt;%\n  summarize(count = n()) %&gt;%\n  arrange(desc(count))))\n\n\n\n\n\ncoach\ncount\n\n\n\n\nRon Rivera\n897\n\n\nBill Belichick\n892\n\n\nJohn Harbaugh\n881\n\n\nMike Tomlin\n879\n\n\nPete Carroll\n878\n\n\nAndy Reid\n791"
  },
  {
    "objectID": "feature_record.html#random-guessing",
    "href": "feature_record.html#random-guessing",
    "title": "Record Data",
    "section": "Random Guessing",
    "text": "Random Guessing\n\n\nCode\nrng = np.random.default_rng(621)\ndf = pd.read_csv(\"data/df.csv\")\nbelichick = df[df['coach'] == 'Bill Belichick']\nbelichick = belichick.drop(columns =['coach', 'punt_wp'])\nbelichick['random_guess'] = rng.choice([0,1], len(belichick))\n\nf1_random = f1_score(belichick['go'], belichick['random_guess'])\naccuracy_random = accuracy_score(belichick['go'], belichick['random_guess'])\nmetrics = pd.DataFrame({\"Metric\" : [\"F1 Score\", \"Accuracy Score\"],\n  \"Random Guessing\" : [f1_random, accuracy_random]})\nmetrics\n\n\n           Metric  Random Guessing\n0        F1 Score            0.202\n1  Accuracy Score            0.503"
  },
  {
    "objectID": "feature_record.html#most-frequent-label",
    "href": "feature_record.html#most-frequent-label",
    "title": "Record Data",
    "section": "Most Frequent Label",
    "text": "Most Frequent Label\n\n\nCode\nmost_frequent_label = int(belichick['go'].mode())\n\n\n&lt;string&gt;:1: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n\n\nCode\nbelichick['frequent'] = most_frequent_label\nf1_random = f1_score(belichick['go'], belichick['frequent'])\naccuracy_random = accuracy_score(belichick['go'], belichick['frequent'])\nmetrics = pd.DataFrame({\"Metric\" : [\"F1 Score\", \"Accuracy Score\"],\n  \"Random Guessing\" : [f1_random, accuracy_random]})\nmetrics\n\n\n           Metric  Random Guessing\n0        F1 Score            0.000\n1  Accuracy Score            0.878"
  },
  {
    "objectID": "feature_record.html#iteration",
    "href": "feature_record.html#iteration",
    "title": "Record Data",
    "section": "Iteration",
    "text": "Iteration\n\n\nMaximize CFS function\nimport itertools\n\ndef maximize_CFS(x,y):\n     k = x.shape[1]\n     max_merit = 0\n     list1 = [*range(0, k)]; #print(list1)\n     for L in range(2, len(list1) + 1):\n          for subset in itertools.combinations(list1, L):\n               m = merit(x[: ,subset], y)\n               if(m &gt; max_merit):\n                    max_merit = m\n                    optimal_subset = subset\n                    print(\"found new max: \", max_merit, \"optimal features = \", list(subset))\n     return(x[:, optimal_subset])\n\n\n\nx_opt=maximize_CFS(x,y)\n\nfound new max:  0.052032118935946704 optimal features =  [0, 1]\nfound new max:  0.11368768322796939 optimal features =  [0, 2]\nfound new max:  0.8816748733067931 optimal features =  [0, 4]\nfound new max:  1.1236893032097657 optimal features =  [2, 6]\nfound new max:  2.524962497621214 optimal features =  [3, 10]\n\nexplore_data(x_opt, y, iplot = False)\n\n(892, 2)\n(892, 1)\nmerit = 18.98937542410711\nmerit = 2.524962497621214\n\nfeatures_opt = pd.DataFrame(x_opt, columns = feature_matrix.columns[[3,10]])\n\nfeatures_opt\n\n     yardline_100  fg_make_prob\n0          29.000         0.773\n1          74.000         0.000\n2          77.000         0.000\n3          35.000         0.668\n4          14.000         0.937\n..            ...           ...\n887        42.000         0.357\n888         6.000         0.982\n889        47.000         0.000\n890        36.000         0.566\n891        75.000         0.000\n\n[892 rows x 2 columns]"
  },
  {
    "objectID": "feature_record.html#merit-score",
    "href": "feature_record.html#merit-score",
    "title": "Record Data",
    "section": "Merit Score",
    "text": "Merit Score\n\\[ \\mathrm {Merit} _{S_{k}}={\\frac {k|{\\overline {r_{cf}}|}}{\\sqrt {k+k(k-1)|{\\overline {r_{ff}}}|}}}  \\]\n\n\nCode\nfrom scipy.stats import spearmanr\n\n#compute base merit score s_2\n\nincluded_vars_s2 = ['fg_make_prob','yardline_100']\nincluded_vars_df = feature_matrix[included_vars_s2].copy()\nfg_yardline_corr = spearmanr(included_vars_df['fg_make_prob'], \n                                  included_vars_df['yardline_100']).statistic\nprint(\"fg_make_prob/yardline_100 correlation: \", round(fg_yardline_corr, 3))\n\n\nfg_make_prob/yardline_100 correlation:  -0.91\n\n\nCode\nfg_go_corr = spearmanr(included_vars_df['fg_make_prob'], label_vec).statistic\n\nprint(\"fg_make_prob/go correlation: \", round(fg_go_corr, 3))\n\n\nfg_make_prob/go correlation:  0.236\n\n\nCode\nyardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic\nprint(\"yardline_100/go correlation: \", round(yardline_go_corr, 3))\n\n\nyardline_100/go correlation:  -0.238\n\n\nCode\nk = 2\n\n# since we only have two features there is only one correlation value, so this mean is just the one value\nmean_xx_corr = fg_yardline_corr #r_{xx}\n\n# mean_xy_corr is the mean of the two feature/label correlations from above\nmean_xy_corr = np.mean([fg_go_corr, yardline_go_corr]) #r_{xy}\n\nprint(f\"Number of Features: {k}\")\n\n\nNumber of Features: 2\n\n\nCode\nmerit_score_numer = k * np.absolute(mean_xy_corr)\nmerit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))\nmerit_score_s2 = merit_score_numer / merit_score_denom\n\n\n\nComputing Fucntions\n\n\nComputing Functions\ndef compute_mean_xx_corr(x_df):\n  df_colnames = x_df.columns\n  # This will contain our final set of x&lt;-&gt;x correlations\n  xx_corrs = []\n  # Now we use itertools to iterate over all possible *pairs* of\n  # elements from df_cols\n  df_colname_pairs = itertools.combinations(df_colnames, 2)\n  for colname1, colname2 in df_colname_pairs:\n    # Extract the first column we're considering\n    col1 = x_df[colname1]\n    # Extract the second column\n    col2 = x_df[colname2]\n    # And compute the correlation\n    xx_pair_corr = spearmanr(col1, col2).statistic\n    xx_corrs.append(xx_pair_corr)\n  # And now that the loop has finished running, we can return the **mean**\n  # of the correlation values we've accumulated in the `xx_corrs` list\n  return np.mean(xx_corrs)\n\ndef compute_mean_xy_corr(x_df, y_vec):\n  df_colnames = x_df.columns\n  xy_corrs = []\n  for colname in df_colnames:\n    x_col = x_df[colname]\n    xy_pair_corr = spearmanr(x_col, y_vec)\n    xy_corrs.append(xy_pair_corr)\n  # And return the mean\n  return np.mean(xy_corrs)\n\nincluded_vars_sp3 = ['half_seconds_remaining','yardline_100', 'score_diff']\nincluded_vars_df = feature_matrix[included_vars_sp3].copy()\nmean_xx_corr = compute_mean_xx_corr(included_vars_df)\nmean_xy_corr = compute_mean_xy_corr(included_vars_df, label_vec)\nmean_xx_corr, mean_xy_corr\n\n\n(0.006391793705608234, -0.0911791098307761)\n\n\nComputing Functions\ndef compute_merit_score(num_features, mean_xx_corr, mean_xy_corr):\n  merit_score_numer = k * np.absolute(mean_xy_corr)\n  merit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))\n  merit_score = merit_score_numer / merit_score_denom\n  return merit_score\n\nmerit_score_sp3 = compute_merit_score(3, mean_xx_corr, mean_xy_corr)\n\n\nincluded_vars_sp5 = ['half_seconds_remaining','yardline_100', 'score_diff', 'posteam_score', 'defteam_score']\nincluded_vars_df = feature_matrix[included_vars_sp5].copy()\nmean_xx_corr = compute_mean_xx_corr(included_vars_df)\nmean_xy_corr = compute_mean_xy_corr(included_vars_df, label_vec)\nmean_xx_corr, mean_xy_corr\n\n\n(-0.023770593024457033, 0.04982235953734039)\n\n\nComputing Functions\nmerit_score_sp5 = compute_merit_score(5, mean_xx_corr, mean_xy_corr)\n\nprint(f\"Merit score (S_2): {merit_score_s2}\")\n\n\nMerit score (S_2): 0.0008591380519168607\n\n\nComputing Functions\nprint(f\"Merit score (S'_3): {merit_score_sp3}\")\n\n\nMerit score (S'_3): 0.12772793283122458\n\n\nComputing Functions\nprint(f\"Merit score (S'_5): {merit_score_sp5}\")\n\n\nMerit score (S'_5): 0.06807401237549958\n\n\n\n\nEvaluate New Model\n\ncoach = \"Ron Rivera\"\n\ncoach_df = df[df['coach'] == coach]\ncoach_df = coach_df.drop(columns = ['punt_wp'])\n\nfeature_matrix = coach_df.drop(columns = ['go', 'coach'])\nfeature_matrix = feature_matrix.apply(zscore)\nlabel_vec = coach_df[['go']]\n\nfeature_matrix_s3 = feature_matrix[included_vars_sp3].copy()\nX_train, X_test, y_train, y_test = train_test_split(feature_matrix_s3, label_vec, test_size=0.2, random_state=621)\n\nmodel = GaussianNB()\nmodel.fit(X_train, np.ravel(y_train))\n\nGaussianNB()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GaussianNBGaussianNB()\n\ntest_predictions = model.predict(X_test)\n\nfs_clf_f1 = f1_score(y_true = y_test, y_pred = test_predictions)\naccuracy_gaussianNB = accuracy_score(y_true = y_test, y_pred = test_predictions)\n\nprint(f\"Feature Selection Model F1: {fs_clf_f1}\")\n\nFeature Selection Model F1: 0.21428571428571427\n\nprint(f\"Accuracy: {accuracy_gaussianNB}\")\n\nAccuracy: 0.8777777777777778"
  },
  {
    "objectID": "data_cleaning1.html",
    "href": "data_cleaning1.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "By Play\n\n\nImports\nlibrary(nflverse)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(reticulate)\nlibrary(kableExtra)\nuse_condaenv(\"r-env\")\noptions(scipen = 999)\n\n# raw_nfl &lt;- load_4th_pbp(2016:2022)\n\n\n\n\nCode\nload(\"data/raw_nfl.Rdata\")\n\n\nWe start with the raw 4th down data from the nflverse package. The first six rows and eight columns can be seen here.\n\n\nCode\nhead(raw_data)\n\n\n── nflverse play by play data ──────────────────────────────────────────────────\n\n\nℹ Data updated: 2022-09-27 06:56:59 EDT\n\n\n# A tibble: 6 × 383\n  play_id game_id      old_game_id home_team away_team season_type  week posteam\n    &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;  \n1       1 2016_01_BUF… 2016091101  BAL       BUF       REG             1 &lt;NA&gt;   \n2      36 2016_01_BUF… 2016091101  BAL       BUF       REG             1 BAL    \n3      58 2016_01_BUF… 2016091101  BAL       BUF       REG             1 BAL    \n4      85 2016_01_BUF… 2016091101  BAL       BUF       REG             1 BAL    \n5     109 2016_01_BUF… 2016091101  BAL       BUF       REG             1 BAL    \n6     130 2016_01_BUF… 2016091101  BAL       BUF       REG             1 BAL    \n# ℹ 375 more variables: posteam_type &lt;chr&gt;, defteam &lt;chr&gt;, side_of_field &lt;chr&gt;,\n#   yardline_100 &lt;dbl&gt;, game_date &lt;chr&gt;, quarter_seconds_remaining &lt;dbl&gt;,\n#   half_seconds_remaining &lt;dbl&gt;, game_seconds_remaining &lt;dbl&gt;,\n#   game_half &lt;chr&gt;, quarter_end &lt;dbl&gt;, drive &lt;dbl&gt;, sp &lt;dbl&gt;, qtr &lt;dbl&gt;,\n#   down &lt;dbl&gt;, goal_to_go &lt;dbl&gt;, time &lt;chr&gt;, yrdln &lt;chr&gt;, ydstogo &lt;dbl&gt;,\n#   ydsnet &lt;dbl&gt;, desc &lt;chr&gt;, play_type &lt;chr&gt;, yards_gained &lt;dbl&gt;,\n#   shotgun &lt;dbl&gt;, no_huddle &lt;dbl&gt;, qb_dropback &lt;dbl&gt;, qb_kneel &lt;dbl&gt;, …\n\n\nThere are a large number of columns in this data, taken from the 2022 NFL season, we do not need all 383. The purpose of this data is to help determine how coaches today approach 4th down, a basic yet essential decision in the NFL. To do this we only need to look at these columns:\n\n\nCode\nfourth_downs &lt;- raw_data %&gt;%\n    filter(!is.na(go_boost) & !is.na(go)) %&gt;%\n    select(season, home_coach, away_coach, posteam, defteam, posteam_type, qtr, time, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)\n\nkable(head(fourth_downs))\n\n\n\n\n\nseason\nhome_coach\naway_coach\nposteam\ndefteam\nposteam_type\nqtr\ntime\nydstogo\nyardline_100\nposteam_score\ndefteam_score\ngo_boost\ngo\nepa\nwp_fail\nwp_succeed\nwp\nfg_make_prob\nmiss_fg_wp\nmake_fg_wp\npunt_wp\n\n\n\n\n2016\nJohn Harbaugh\nRex Ryan\nBAL\nBUF\nhome\n1\n12:05\n1\n66\n0\n0\n1.8427797\n0\n-0.9226208\n0.4501592\n0.5882827\n0.5102725\n0.0000000\n0.4320890\n0.5741632\n0.5265389\n\n\n2016\nJohn Harbaugh\nRex Ryan\nBAL\nBUF\nhome\n1\n11:52\n6\n71\n0\n0\n-1.1323169\n0\n-0.4050476\n0.4403515\n0.5971214\n0.4710029\n0.0000000\n0.4196399\n0.5725211\n0.5166918\n\n\n2016\nJohn Harbaugh\nRex Ryan\nBUF\nBAL\naway\n1\n09:42\n18\n76\n0\n0\n-5.7820437\n0\n0.2241808\n0.3423280\n0.5154754\n0.4189611\n0.0000000\n0.3280475\n0.5250292\n0.4171238\n\n\n2016\nJohn Harbaugh\nRex Ryan\nBUF\nBAL\naway\n1\n05:30\n6\n43\n0\n0\n2.0073829\n0\n-0.4404633\n0.3919702\n0.5667855\n0.4749633\n0.0000000\n0.3907058\n0.5210628\n0.4426614\n\n\n2016\nJohn Harbaugh\nRex Ryan\nBUF\nBAL\naway\n1\n05:30\n11\n48\n0\n0\n-0.6287521\n0\n0.4479581\n0.3906138\n0.5670854\n0.4759269\n0.0000000\n0.3771124\n0.5210628\n0.4410649\n\n\n2016\nJohn Harbaugh\nRex Ryan\nBAL\nBUF\nhome\n1\n00:41\n15\n32\n0\n0\n-4.0096273\n0\n1.7974257\n0.5135549\n0.6866364\n0.5298005\n0.6625606\n0.4986032\n0.6224666\n0.5387274\n\n\n\n\n\n\n\nEach unit in this table is one 4th down decision. The variables include:\n\n\nCode\ncodebook &lt;- data.frame(\"Variable\" = names(fourth_downs),\n                       \"Description\" = c(\"Season\",\n                                     \"Home Team Coach\",\n                                     \"Away Team Coach\",\n                                     \"Offense Team\",\n                                     \"Defense Team\",\n                                     \"Offense Home or Away\",\n                                     \"Quarter\",\n                                     \"Time left in Quarter\",\n                                     \"Yards to Go\",\n                                     \"Yardline Relative to End Zone\",\n                                     \"Offense Score\",\n                                     \"Defense Score\",\n                                     \"Change in Win Probability if Conversion Attempted\",\n                                     \"Conversion Attempted (T/F)\",\n                                     \"Estimated Points Added as a Result of the Play\",\n                                     \"Win Probability if Conversion Fails\",\n                                     \"Win Probability if Conversion Succeeds\",\n                                     \"Win Probability at Time of Play\",\n                                     \"Chance of Making Field Goal\",\n                                     \"Win Probability if Field Goal Misses\",\n                                     \"Win Probability if Field Goal is Made\",\n                                     \"Win Probability if Team Punts\"))\n\nkable(codebook)\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nseason\nSeason\n\n\nhome_coach\nHome Team Coach\n\n\naway_coach\nAway Team Coach\n\n\nposteam\nOffense Team\n\n\ndefteam\nDefense Team\n\n\nposteam_type\nOffense Home or Away\n\n\nqtr\nQuarter\n\n\ntime\nTime left in Quarter\n\n\nydstogo\nYards to Go\n\n\nyardline_100\nYardline Relative to End Zone\n\n\nposteam_score\nOffense Score\n\n\ndefteam_score\nDefense Score\n\n\ngo_boost\nChange in Win Probability if Conversion Attempted\n\n\ngo\nConversion Attempted (T/F)\n\n\nepa\nEstimated Points Added as a Result of the Play\n\n\nwp_fail\nWin Probability if Conversion Fails\n\n\nwp_succeed\nWin Probability if Conversion Succeeds\n\n\nwp\nWin Probability at Time of Play\n\n\nfg_make_prob\nChance of Making Field Goal\n\n\nmiss_fg_wp\nWin Probability if Field Goal Misses\n\n\nmake_fg_wp\nWin Probability if Field Goal is Made\n\n\npunt_wp\nWin Probability if Team Punts\n\n\n\n\n\n\n\n\n\nDecisions\nMaking a table showing when coaches make the correct decisions on 4th down is essential in evaluating their decision making process. This is made easy by the inclusion of the go_boost variable, which tells us the change in win probability if the team decides to go for it.\n\n\nCode\nfourth_decisions &lt;- fourth_downs %&gt;%\n    mutate(should_go = ifelse((go_boost &gt; 0),\n                             (if_else(go == 100, 1, 0)),\n                             NA),\n          shouldnt_go = ifelse((go_boost &lt; 0),\n                             (if_else(go == 0, 1, 0)),\n                             NA),\n           coach = if_else(posteam_type == \"home\", home_coach, away_coach),) %&gt;%\n    select(season, coach, posteam, ydstogo, yardline_100, go_boost, should_go, shouldnt_go, go, epa) %&gt;%\n    group_by(coach, posteam, season) %&gt;%\n    summarize(should_go = \n                sum(should_go == 1, na.rm = TRUE) / \n                (sum(should_go == 0 | should_go == 1, na.rm = TRUE)),\n              shouldnt_go = \n                sum(shouldnt_go == 1, na.rm = TRUE) / \n                (sum(shouldnt_go == 0 | shouldnt_go == 1, na.rm = TRUE)),\n              EPA = mean(epa),\n              count = n()) %&gt;%\n    filter(count &gt; 50) %&gt;%\n  ungroup()\n\nkable(head(fourth_decisions))\n\n\n\n\n\ncoach\nposteam\nseason\nshould_go\nshouldnt_go\nEPA\ncount\n\n\n\n\nAdam Gase\nMIA\n2016\n0.0750000\n0.9746835\n-0.2775340\n119\n\n\nAdam Gase\nMIA\n2017\n0.3750000\n0.8901099\n-0.1325974\n131\n\n\nAdam Gase\nMIA\n2018\n0.2105263\n1.0000000\n-0.0207982\n123\n\n\nAdam Gase\nNYJ\n2019\n0.3400000\n0.9759036\n-0.1713117\n133\n\n\nAdam Gase\nNYJ\n2020\n0.2372881\n0.9420290\n-0.3822222\n128\n\n\nAndy Reid\nKC\n2016\n0.2692308\n1.0000000\n0.2303307\n134\n\n\n\n\n\n\n\nThis data shows when coaches make the correct choice on 4th down, their average estimated points added on 4th downs throughout the season, and the number of 4th down decisions they had to make throughout the season. It shows the percent of times each coach makes the correct decision in two scenarios: when going for it would have a positive effect on their win probability and when going for it would have a negative effect on their win probability.\n\n\nBy Situation\nOne of, if not the most important factor in making a decision on fourth down is the position your team is on the field. Looking at this more closely requires a table that shows coaches decisions based on where they are on the field and how many downs they need to gain to get a first down.\n\n\nCode\nfourth_position &lt;- fourth_downs %&gt;%\n  mutate(expected_go = ifelse(go_boost &gt; 0, 1, 0)) %&gt;%\n  select(yardline_100,\n         ydstogo,\n         go,\n         expected_go,\n         go_boost) %&gt;%\n  group_by(yardline_100, ydstogo) %&gt;%\n  summarize(actual_go = mean(go)/100,\n            expected_go = mean(expected_go, na.rm = TRUE),\n            count = n(),\n            go_boost = mean(go_boost),\n            increase_odds = ifelse(go_boost &gt; 0, 1, 0))\n\nkable(head(fourth_position))\n\n\n\n\n\nyardline_100\nydstogo\nactual_go\nexpected_go\ncount\ngo_boost\nincrease_odds\n\n\n\n\n1\n1\n0.8203390\n0.9559322\n295\n4.9600474\n1\n\n\n2\n1\n0.7083333\n0.8750000\n24\n4.8919987\n1\n\n\n2\n2\n0.4090909\n0.8522727\n176\n2.3801234\n1\n\n\n3\n1\n0.7666667\n0.9333333\n30\n5.8391101\n1\n\n\n3\n2\n0.4500000\n0.7500000\n20\n1.6188433\n1\n\n\n3\n3\n0.2303030\n0.6545455\n165\n0.8065048\n1\n\n\n\n\n\n\n\nThis table shows us the percentage of times a coach chose to go for it in the given situation. The first row, for example, shows that 80% of the time a coach decided to go for it when they were at 4th and 1 at the 1 yard line - they were 1 yard away from scoring. It also shows is the average increase in win probability if a coach were to go for it. For example, at 4th and 1 at the 1 yard line, going for it increases your win probability by an average of 5%, an incredibly large number.\n\n\nCode\nsave(fourth_decisions, fourth_downs, fourth_position, file = \"data/clean_data.Rdata\")\n\n\n\n\nDecision Trees\nFor our decision tree building, we would like to format our play by play data in a slightly different manner. Mainly, we want to only have the coach of the team on offense as we are evaluating their deicion-making, not the defensive team’s coach. Also, we want to drop unnecessary columns and make a singular score_diff column, rather than have separate columns for posteam_score and defteam_score. The resultant table can be seen below, and is used in our decision tree analysis later on in the project.\n\n\nCode\nload(\"data/raw_nfl.Rdata\")\ndf &lt;- raw_data %&gt;%\n    filter(!is.na(go_boost) & !is.na(go)) %&gt;%\n    select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)\ndf &lt;- df %&gt;%\n  mutate(coach = if_else(posteam_type == \"home\", home_coach, away_coach),\n         home_coach = coach,\n         score_diff = posteam_score - defteam_score,\n         go = if_else(go == 100, 1, 0),\n         game_half = if_else(game_half == \"Half1\", 1, 2)) %&gt;%\n  select(-coach,\n         -away_coach,\n         -season,\n         -posteam,\n         -defteam,\n         -posteam_type,\n         -epa,\n         -punt_wp,\n         -posteam_score,\n         -defteam_score) %&gt;%\n  rename(coach = home_coach) %&gt;%\n  select(-go, everything())\nwrite.csv(df, \"data/dt.csv\")\n\nkable(head(df))\n\n\n\n\n\ncoach\ngame_half\nhalf_seconds_remaining\nydstogo\nyardline_100\ngo_boost\nwp_fail\nwp_succeed\nwp\nfg_make_prob\nmiss_fg_wp\nmake_fg_wp\nscore_diff\ngo\n\n\n\n\nJohn Harbaugh\n1\n1625\n1\n66\n1.8427797\n0.4501592\n0.5882827\n0.5102725\n0.0000000\n0.4320890\n0.5741632\n0\n0\n\n\nJohn Harbaugh\n1\n1612\n6\n71\n-1.1323169\n0.4403515\n0.5971214\n0.4710029\n0.0000000\n0.4196399\n0.5725211\n0\n0\n\n\nRex Ryan\n1\n1482\n18\n76\n-5.7820437\n0.3423280\n0.5154754\n0.4189611\n0.0000000\n0.3280475\n0.5250292\n0\n0\n\n\nRex Ryan\n1\n1230\n6\n43\n2.0073829\n0.3919702\n0.5667855\n0.4749633\n0.0000000\n0.3907058\n0.5210628\n0\n0\n\n\nRex Ryan\n1\n1230\n11\n48\n-0.6287521\n0.3906138\n0.5670854\n0.4759269\n0.0000000\n0.3771124\n0.5210628\n0\n0\n\n\nJohn Harbaugh\n1\n941\n15\n32\n-4.0096273\n0.5135549\n0.6866364\n0.5298005\n0.6625606\n0.4986032\n0.6224666\n0\n0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "In sports, as in all areas of life, there are a variety of decisions that actors can make as their game or competition unfolds. As a result, there are numerous decisions that can be made, each coming with their own level of risk. Some decisions are obvious, like tagging up from third base on a deep fly ball with less than two outs or punting on fourth and long when back at your own end zone. However, many more appear to not be so obvious, as evidenced by the variety of opinions that arise when observing these choices in action. Despite numerous advancements in analysis in many sports, decisions are still heavily debated on a daily basis. Even if analysis on other similar situations suggests one decision should be made, we often see the exact opposite on the field. Ward Edwards, in his 1954 paper “The theory of decision making” introduces this well, saying “The traditional mathematical notion for dealing with games of chance (and so with risky decisions) is the notion that choices should be made so as to maximize expected value… The assumption that people actually behave the way this mathematical notion says they should is contradicted by observable behavior in many risky situations” (Edwards 1954, 391).\nWhy do people behave this way? It goes against what we know about expected value and suggests that we are illogical actors. This is elaborated further by Daniel Kahneman and Amos Tversky in their influential 1979 paper “Prospect Theory: an Analysis of Decision Under Risk” in which they explain, “Choices among risky prospects exhibit several pervasive effects that are inconsistent with the basic tenets of utility theory” (Kahneman and Tversky 1979). This eventually leads them to an alternative theory of choice “in which value is assigned to gains and losses rather than to final assets and in which probabilities are replaced by decision weights” (Kahneman and Tversky 1979).\nTo better understand decision making, we will do as David Romer did in his 2006 paper “Do Firms Maximize? Evidence from Professional Football” (Romer 2006). We will focus specifically on one of the most important decisions certainly in football but perhaps in all of sports: 4th down. Focusing on this decision and attempting to understand the reasoning behind why it is so frequently done incorrectly will hopefully allow us to learn more about the decision making process not only in football, but in many other areas of life.\n\n\nThis project will focus specifically on one critical and often scrutinized decision: 4th downs in the National Football League. Here I will provide a breif overview of what this decision entails for those who may not be as familiar with the game of football. Even for those who are familiar, this section may be useful to understand how I will approach this decision throughout the project.\n\n\nTo start I will clear up some terminology. To “go for it” is to attempt a first down conversion and conversely to “not go for it” is to not attempt a conversion. In football the offense has four chances, or “downs” to advance the ball 10 yards towards their goal (yards are denoted by markings on the field). If they are ever able to advance that 10 yards, the counter resets and they have another four chances to advance the ball another 10 yards. This is how teams progress down the field towards their goal. If, after their fourth chance (their fourth “down”), they have not advanced the ball the required 10 yards, the opposing team gains possession and is now on offense, attempting to advance in the same manner in the other direction.\nThe caveat and the reason this becomes a difficult decision is if a team does not get the required 10 yards, the opposing team gains possesion wherever the offenseive team is stopped on 4th down. Because the other team is attempting to progress the ball in the opposite direction, if this change occurs after very little advancement by the team on offense, the opposing team gets the ball in a favorable position.\nThere is another alternative to “going for it” on fourth down (attempting to gain the yards needed to reset the down count). A team can elect to “punt”, meaning they dropkick the ball to the opposing team who will recieve it and start their possession further down the field. See the diagram below for a comparison of the two scenarios. The team on offense has the ball at the blue line, and must gain 10 yards (the yellow line) to reset the down count to first down. If they fail to gain those yards on fourth down, the opposing team gets the ball far closer to their goal than if they elect to punt, as evidenced by the location of the left-most blue line.\n\nHowever, there is one other alternative beyond going for it and punting on fourth down. Kicking a field goal is worth 3 points in the NFL, and is typically attempted when a team is about 40 yards or less away from their goal. In the above diagram a field goal would not be an option as the team is 70 yards (50 + 20) away from their goal.\nTo summarize, a team will either attempt a conversion on 4th down (go for it) or they will not (not go for it). If they choose to not go for it, they can either punt or attempt a field goal though for the purpose of this project those will both be treated as the same scenario (not going for it). Throughout the project, this binary decision will be represented as such:\n0: Not go for it (field goal or punt)\n1: Go for it (run a play)"
  },
  {
    "objectID": "index.html#th-down",
    "href": "index.html#th-down",
    "title": "Introduction",
    "section": "",
    "text": "This project will focus specifically on one critical and often scrutinized decision: 4th downs in the National Football League. Here I will provide a breif overview of what this decision entails for those who may not be as familiar with the game of football. Even for those who are familiar, this section may be useful to understand how I will approach this decision throughout the project.\n\n\nTo start I will clear up some terminology. To “go for it” is to attempt a first down conversion and conversely to “not go for it” is to not attempt a conversion. In football the offense has four chances, or “downs” to advance the ball 10 yards towards their goal (yards are denoted by markings on the field). If they are ever able to advance that 10 yards, the counter resets and they have another four chances to advance the ball another 10 yards. This is how teams progress down the field towards their goal. If, after their fourth chance (their fourth “down”), they have not advanced the ball the required 10 yards, the opposing team gains possession and is now on offense, attempting to advance in the same manner in the other direction.\nThe caveat and the reason this becomes a difficult decision is if a team does not get the required 10 yards, the opposing team gains possesion wherever the offenseive team is stopped on 4th down. Because the other team is attempting to progress the ball in the opposite direction, if this change occurs after very little advancement by the team on offense, the opposing team gets the ball in a favorable position.\nThere is another alternative to “going for it” on fourth down (attempting to gain the yards needed to reset the down count). A team can elect to “punt”, meaning they dropkick the ball to the opposing team who will recieve it and start their possession further down the field. See the diagram below for a comparison of the two scenarios. The team on offense has the ball at the blue line, and must gain 10 yards (the yellow line) to reset the down count to first down. If they fail to gain those yards on fourth down, the opposing team gets the ball far closer to their goal than if they elect to punt, as evidenced by the location of the left-most blue line.\n\nHowever, there is one other alternative beyond going for it and punting on fourth down. Kicking a field goal is worth 3 points in the NFL, and is typically attempted when a team is about 40 yards or less away from their goal. In the above diagram a field goal would not be an option as the team is 70 yards (50 + 20) away from their goal.\nTo summarize, a team will either attempt a conversion on 4th down (go for it) or they will not (not go for it). If they choose to not go for it, they can either punt or attempt a field goal though for the purpose of this project those will both be treated as the same scenario (not going for it). Throughout the project, this binary decision will be represented as such:\n0: Not go for it (field goal or punt)\n1: Go for it (run a play)"
  },
  {
    "objectID": "fourth_decisions.html",
    "href": "fourth_decisions.html",
    "title": "4th Down Decisions",
    "section": "",
    "text": "Inputs and Setup\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(reticulate)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(plotly)\nlibrary(RColorBrewer)\nlibrary(scales)\nuse_condaenv(\"r-env\")\noptions(scipen = 999)\n\nload(\"data/clean_data.Rdata\")\n\n\nWe will initially explore the data in a similar manner to the method seen in David Romer’s paper (Romer 2006). In his evaluation of fourth down decisions, he followed a four step process. First, he estimated the value of kicking (not going for it). Second, he estimated the value of going for it. Third, he figured out which decision was better. Finally, he compared this to the actual decisions made by coaches.\nThanks again to the nflverse package, we already have completed steps one and two as we can simply use the go_boost variable to estimate the value of kicking or going for it on each fourth down. Step three was already completed in the cleaning process, as we already have a table that takes into account the fact that if go_boost is negative, then the offensive team should kick. If go_boost is positive, then they should go for it. We have all the information to evaluate theoretical decisions, now we must evaluate the actual decisions made by coaches.\n\n4th Down Statistics\nHow often do coaches make the correct decision on 4th down?\n\n\nCode\np &lt;- ggplot(data = fourth_decisions, aes(x = should_go)) + \n  geom_histogram(binwidth = 0.05, fill = \"#69b3a2\", color=\"#e9ecef\") +\n  scale_x_continuous(limits = c(0, 1.1), breaks = seq(0, 1, by = 0.1)) +\n  scale_y_continuous(limits = c(0, 70)) +\n  ggtitle(\"When NFL Coaches Go When They Should\") +\n  xlab(\"\") +\n  stat_bin(binwidth = 0.05, \n           geom='text', \n           aes(label=ifelse(..count.. != 0, ..count.., \"\")), \n           vjust = -0.5)\np1 &lt;- ggplot(data = fourth_decisions, aes(x = shouldnt_go)) + \n  geom_histogram(binwidth = 0.05, fill = \"#69b3a2\", color=\"#e9ecef\") +\n  scale_x_continuous(limits =c(0, 1.1), breaks = seq(0, 1, by = 0.1)) +\n  scale_y_continuous(limits = c(0, 200)) +\n  ggtitle(\"When NFL Coaches Don't Go When They Shouldn't\") +\n  xlab(\"\") +\n  stat_bin(binwidth = 0.05, \n           geom='text', \n           aes(label=ifelse(..count.. != 0, ..count.., \"\")), \n           vjust = -0.5)\n\ngrid.arrange(p, p1, ncol = 1)\n\n\n\n\n\nWe can see a clear difference between these two plots when they are put on the same scale. When it would be a “correct” decision to kick rather than go for it (when win probability would go down if a conversion was attempted) coaches often make the correct decision. Every coach was correct in these situations at least 90% which makes sense because these decisions are often easy to make. They are not the borderline decisions that we can learn a lot about coaches from. For those we turn to the first graph, where we can clearly see that the decision on whether or not to go for it when doing so would increase your win probability is much more difficult, as only two coaches got this one right over 50% of the time. Let’s look at this decision more closely and see what turns coaches away from going for it even when they should be.\n\n\nCode\nfourth_position &lt;- fourth_position %&gt;%\n  filter(count &gt; 10)\nplot_ly(data = fourth_position, \n        x = ~yardline_100, \n        y = ~ydstogo,\n        text = ~paste(\"go:\", actual_go, \"&lt;br&gt;count:\", count),\n        type = \"scatter\",\n        mode = \"markers\",\n        marker = list(size = 8),\n        color = ~actual_go,\n        colors = (c(\"#FF0000\", \"#ecf54e\", \"#008000\"))) %&gt;%\n  layout(title = \"When Coaches Actually Go For It\",\n         xaxis = list(title = \"Yardline (Yards from Endzone)\",\n                      dtick = 10,\n                      tick0 = 0,\n                      tickmode = \"linear\"),\n         yaxis = list(title = \"Yards to Go\",\n                      dtick = 5,\n                      tick0 = 0,\n                      tickmode = \"linear\")) %&gt;%\n  colorbar(title = \"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first graph is colored based on the proportion of plays in which a coach decides to go for it when doing so would have a positive impact on their win probability. The second graph is colored based on the proportion of plays in which going for it would have a positive impact on their win probability, regardless of whether or not a coach actually decided to go for it.\nThese graphs clearly show that coaches in the NFL are far too conservative. The only situation in which they consistently go for it is on 4th and 1 inside the 50. The data suggest that they should actually always go for it when there are less than 2 yards to go and almost always go for it within 5 yards. Coaches are consistently far too conservative in situations when it is clearly advantageous to attempt a 4th down conversion. Why might this be the case? Let’s perform some EDA to come up with some possible explanations.\n\n\n\n\n\nReferences\n\nRomer, David. 2006. “Do Firms Maximize? Evidence from Professional Football.” Journal of Political Economy 114 (2): 340–65. https://doi.org/10.1086/501171."
  },
  {
    "objectID": "data_gathering.html",
    "href": "data_gathering.html",
    "title": "Data Gathering",
    "section": "",
    "text": "Data\nData to evaluate NFL decision making was gathered by using the nflreadr package. The creators of this package provide detailed instructions and examples on how to use and clean this data, which can be found at their website here.\nReddit data is accessed through their API, information on which can be found here. This is done using PRAW: the Python Reddit API Wrapper."
  },
  {
    "objectID": "high_leverage_scenarios.html",
    "href": "high_leverage_scenarios.html",
    "title": "High-Leverage Scenarios",
    "section": "",
    "text": "Inputs and Setup\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(reticulate)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(plotly)\nlibrary(RColorBrewer)\nlibrary(scales)\noptions(digits = 3)\n\nload(\"data/clean_data.Rdata\")\n\n\n\nIsolate Scenarios\nNot all 4th down decisions are created equal. Depending on a variety of factors such as score, time of game, field position, and others different 4th down decisions can be a lot more important than others. It would be useful to attempt to isolate those high-leverage situations and explore those as they have the potential to tell us a lot more about decision making tendencies of NFL head coaches.\nFiltering all 4th down decisions by ones that have a difference of at least 20% in resultant win probability base simply on whether the coach decides to go for it or not gives us a good look at those high leverage situations. Filtering the data further by only including situations in which if the coach goes for it and succeeds, then they are almost guaranteed to win the game (wp_succeed &gt; 0.95)\n\n\nFilter Scenarios\nleverage &lt;- fourth_downs %&gt;% \n  mutate(wp_change = wp_succeed - wp_fail,\n         coach = if_else(posteam_type == \"home\", home_coach, away_coach)) %&gt;%\n  select(season,\n         coach,\n         posteam,\n         defteam,\n         qtr,\n         time,\n         ydstogo,\n         yardline_100,\n         posteam_score,\n         defteam_score,\n         go_boost,\n         go,\n         epa,\n         wp,\n         wp_fail,\n         wp_succeed,\n         wp_change,\n         fg_make_prob,\n         miss_fg_wp,\n         make_fg_wp,\n         punt_wp) %&gt;%\n  filter(abs(wp_change) &gt; .2,\n         wp_succeed &gt; .95,\n         qtr == 4)\n\n\nLet’s visualize this data and make it easier to look through using a familiar plot structure.\n\n\nCode\nlabels &lt;- paste(leverage$ydstogo, \"to go /\", leverage$yardline_100, \"yardline\",\n                \"&lt;br&gt;Season: \", leverage$season,\n                \"&lt;br&gt;Coach: \", leverage$coach, \"-\", leverage$posteam, \"&lt;br&gt;\",\n                leverage$posteam_score, \"-\", leverage$defteam_score, \"/\", leverage$time,\n                \"&lt;br&gt;Win Probability: \", sprintf(\"%.2f\", leverage$wp),\n                \"&lt;br&gt;WP Fail / Succeed: \", sprintf(\"%.2f\", leverage$wp_fail), \"/\", sprintf(\"%.2f\", leverage$wp_succeed),\n                \"&lt;br&gt;FG Make Prob: \", sprintf(\"%.2f\", leverage$fg_make_prob),\n                \"&lt;br&gt;Punt WP: \", sprintf(\"%.2f\", leverage$punt_wp),\n                \"&lt;br&gt;go_boost / go: \", sprintf(\"%.2f\",leverage$go_boost), \"/\", leverage$go,\n                \"&lt;extra&gt;&lt;/extra&gt;\")\nplot_ly(data = leverage,\n        x = ~yardline_100, \n        y = ~ydstogo,\n        type = \"scatter\",\n        mode = \"markers\",\n        color = ~go_boost,\n        marker = list(size = 8),\n        hovertemplate = labels) %&gt;%\n  layout(title = \"High Leverage Situations\",\n         xaxis = list(title = \"Yardline (Yards from Endzone)\",\n                      dtick = 10,\n                      tick0 = 0,\n                      tickmode = \"linear\"),\n         yaxis = list(title = \"Yards to Go\",\n                      dtick = 5,\n                      tick0 = 0,\n                      tickmode = \"linear\"))\n\n\n\n\n\n\nI enjoy this plot because it really allows you to put yourself in the shoes of these coaches. All the necessary information is contained in each point when hovered over to make a decision. Try some yourself, hover over a point, get an understanding of the situation, and ask: if I was the coach would I have gone for it? All of these are 4th quarter situations with the game on the line. The final line in the popup is the “answer”, so to speak. If go_boost is positive, then the stats say you should go for it, and if it is negative then you should not. If the number following go_boost is 100, the coach actually did end up going for it, and if it is 0 then they did not go for it (either attempt a field goal or punt). Especially look at the scenarios in which the go_boost is high, meaning it would be a very good decision to go for it. Would you have taken the risk and attempted the conversion? Many coaches do not, despite the fact that it would be the “correct” play. Even after spending a lot of time with these situations, I have a hard time blaming them.\n\n\nA High Leverage Example\nTake this situation for example. You are Vic Fangio, coach of the 2019 Denver Broncos, a struggling team sitting at 2-5 heading into a week 8 match up against the 4-2 Indianapolis Colts. After battling your way through a low-scoring game, you find yourself with the ball with 3:30 left in the game, clinging to a one point lead. All you have to do is hold on and you will get a win against a solid Colts team that could help turn your season around. Just one solid drive down the field will run out the rest of the clock. This turns out to be too much to ask, however, as the drive stalls at the Colts 43-yardline. You have a critical decision to make.\nThe score is 13 - 12, your team is winning. There is 1:55 left in the game. It is 4th and 5 at your opponents 43 yardline (you are 43 yards away from scoring). This is too far for a field goal, as it would be 60 yards which is too far for your kicker to attempt. Your options are as follows:\n\nGo for it and attempt to get the first down. If you pick up the required 5 yards, the game is essentially over and you win. However if you attempt the conversion and do not pick up the first down, then your opponents get the ball back where they stopped you, meaning they do not have far to go (only about 30 yards) themselves to kick a field goal and win the game.\nPunt and give the ball back to the other team near their own end-zone with about 1 minute remaining. They would have to go further to get within field goal range, but you would be giving them the ball back rather than attempting to end the game by picking up the first down.\n\nBelow is a diagram of the situation. The blue line is where you currently have the ball and the yellow line is where you need to advance the ball should you decide to go for it. If you decide to go for it and cannot get to the yellow line, your opponent would get the ball wherever they stopped you, most likely around the blue line. The purple line is where your opponent would need to get to in order to kick a field goal to win the game. As shown on the diagram, a punt would mean they must advance the ball much further to reach that purple line.\n\nWhat would you do here? Make the risky play and attempt to end the game right here and now by getting a first down, but giving your opponent a much better chance to win if you do not get it? Or make the safe play and not even try to end the game, but give your opponent a much lower chance to win than if you failed to reach the yellow line? On that October day back in 2019, Vic Fangio decided to play it safe. He punted the ball so the Colts would get it at their own 11 yard line. They had to go about 60 yards to get into field goal range for Adam Vinateri, their kicker. This is a much further distance than the 20 yards the Colts would have to go if the Broncos failed their 4th down attempt. However this distance did not matter in the end, as the Colts were able to drive 60 yards down the field and kick the game winning field goal with 20 seconds left. Final score: Broncos 13, Colts 15. The Broncos lose and fall to 2-6 at the halfway point of the 2019 NFL season.\nIt would absolutely be unfair to place all of the blame for the loss on this one decision by Vic Fangio here, as there are so many parts to a football game. For example if the Broncos score more than 15 points (a very low number for a football game) then we aren’t even talking about this decision years after it happened. But the purpose of this exercise is to put yourself in the shoes of these coaches and make tough decisions. Even though I know all of the probabilities associated with each outcome in this situation, I still have a hard time making the call to go for it. It took me a long time to think about each option, and if I’m being honest here, that time was mostly spent trying to convince myself that option 1 was incorrect. I’ll bet many of you felt that way too, none of us wanted to take the risky play. It is a lot easier to stomach option 2 because there isn’t that option of catastrophic failure lurking in the background. The potential to instantly win the game is overshadowed by the threat of giving the ball to the other team in such a good position.\nTaking option 1 in this situation resulted in a 10.65% increase in win probability regardless of the outcome (success or failure in the attempt). This should be a clear-cut decision with that kind of increase in win probability. Why is it such a hard decision then? My initial thoughts say that this is the case becasue it is such a big risk to take, as attempting it and failing puts your opponent in a much better position. Just punt it away, take the safe play and make your opponent go win the game, rather than go for it and fail and have loss be on your shoulders. As I said earlier, it is a lot easier to stomach a loss that is the result of conservative decision making than one that is the result of risky decision making."
  },
  {
    "objectID": "dimensionality_reduction.html",
    "href": "dimensionality_reduction.html",
    "title": "Dimensionality Reduction",
    "section": "",
    "text": "Imports and Data\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(reticulate)\nlibrary(gridExtra)\nlibrary(kableExtra)\n\nload(\"data/raw_nfl.Rdata\")\n\n\n\nPrincipal Component Analysis\n\n\nClean Data\ndf &lt;- raw_data %&gt;%\n    filter(!is.na(go_boost) & !is.na(go)) %&gt;%\n    select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)\ndf &lt;- df %&gt;%\n  mutate(coach = if_else(posteam_type == \"home\", home_coach, away_coach),\n         home_coach = coach,\n         score_diff = posteam_score - defteam_score,\n         go = if_else(go == 100, 1, 0),\n         game_half = if_else(game_half == \"Half1\", 1, 2)) %&gt;%\n  select(-coach,\n         -away_coach,\n         -season,\n         -posteam,\n         -defteam,\n         -posteam_type,\n         -epa,\n         -punt_wp,\n         -posteam_score,\n         -defteam_score) %&gt;%\n  rename(coach = home_coach) %&gt;%\n  select(-go, everything())\n\nwrite.csv(df, \"data/df.csv\")\n\nkable(head(df))\n\n\n\n\n\ncoach\ngame_half\nhalf_seconds_remaining\nydstogo\nyardline_100\ngo_boost\nwp_fail\nwp_succeed\nwp\nfg_make_prob\nmiss_fg_wp\nmake_fg_wp\nscore_diff\ngo\n\n\n\n\nJohn Harbaugh\n1\n1625\n1\n66\n1.8427797\n0.4501592\n0.5882827\n0.5102725\n0.0000000\n0.4320890\n0.5741632\n0\n0\n\n\nJohn Harbaugh\n1\n1612\n6\n71\n-1.1323169\n0.4403515\n0.5971214\n0.4710029\n0.0000000\n0.4196399\n0.5725211\n0\n0\n\n\nRex Ryan\n1\n1482\n18\n76\n-5.7820437\n0.3423280\n0.5154754\n0.4189611\n0.0000000\n0.3280475\n0.5250292\n0\n0\n\n\nRex Ryan\n1\n1230\n6\n43\n2.0073829\n0.3919702\n0.5667855\n0.4749633\n0.0000000\n0.3907058\n0.5210628\n0\n0\n\n\nRex Ryan\n1\n1230\n11\n48\n-0.6287521\n0.3906138\n0.5670854\n0.4759269\n0.0000000\n0.3771124\n0.5210628\n0\n0\n\n\nJohn Harbaugh\n1\n941\n15\n32\n-4.0096273\n0.5135549\n0.6866364\n0.5298005\n0.6625606\n0.4986032\n0.6224666\n0\n0\n\n\n\n\n\n\n\n\n\nPython Imports\nimport json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import silhouette_samples, silhouette_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nCode\nX = r.df\nto_drop = [\"coach\", \"go\"]\nX = X.drop(to_drop, axis = 1)\nY = r.df[\"go\"]\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\npca = PCA(n_components = 5).fit(X)\nvariance_ratios = pca.explained_variance_ratio_\n\nplt.cla()\nplt.plot(range(1, len(variance_ratios) + 1), variance_ratios, marker='o')\nplt.xlabel(\"Principal Component\")\nplt.ylabel(\"Prop. Variance Explained\")\nplt.show()\n\n\n\n\n\nThe optimal number of principal components to keep is 2, looking at where the “elbow” is on this graph of the proporition variance explained by each principal component.\n\n\nCode\npca = PCA(n_components =  2).fit(X)\nXp = pca.transform(X)\nXp_df = pd.DataFrame(Xp, columns = ['x', 'y'])\n\n\n\n\nCode\nggplot(data = py$Xp_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"First Principal Component\", y = \"Second Principal Component\") +\n  geom_abline(intercept = 1, slope = 0.3, color = \"black\", linewidth = 1.5) + \n  theme_minimal()\n\n\n\n\n\nWhen graphing the first and second principal components and coloring each based on whether the coach attempted a conversion on the play (0 being no and 1 being yes), we can see some clustering take place. There is a clear main group of points with most of the green points being in the upper left portion of the cluster, and the red points being in the bottom right. There are more red than green points, which makes sense as there are more 4th down plays where coaches did not go for it than ones where they did. There are also some outliers where points increase in the y-direction up to 8. From this analysis, it is worth looking at those outliers to see why they are so far up there, as well as the points that are on the edge of the border between red and green points. I have drawn an approximate line on the graph for demonstration purposes, just to show the area that I think is worth looking at.\n\n\nt-SNE\n\n\nCode\nfrom sklearn.manifold import TSNE\n\n\n\n\nCode\nX_5 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=5, n_iter=300).fit_transform(X)\nX5_df = pd.DataFrame(X_5, columns = ['x', 'y'])\n \nX_10 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=10, n_iter=300).fit_transform(X)\nX10_df = pd.DataFrame(X_10, columns = ['x', 'y'])\n \nX_20 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=20, n_iter=300).fit_transform(X)\nX20_df = pd.DataFrame(X_20, columns = ['x', 'y'])\n \nX_30 = TSNE(n_components=2,learning_rate='auto',init='random',perplexity=30, n_iter=300).fit_transform(X)\nX30_df = pd.DataFrame(X_30, columns = ['x', 'y'])\n\nX_40 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=40, n_iter=300).fit_transform(X)\nX40_df = pd.DataFrame(X_40, columns = ['x', 'y'])\n \nX_50 = TSNE(n_components=2,learning_rate='auto',init='random', perplexity=50, n_iter=300).fit_transform(X)\nX50_df = pd.DataFrame(X_50, columns = ['x', 'y'])\n\n\n\n\nGenerate Plots\np5 &lt;- ggplot(data = py$X5_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 5\")\n\np10 &lt;- ggplot(data = py$X10_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 10\")\n\np20 &lt;- ggplot(data = py$X20_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 20\")\n\np30 &lt;- ggplot(data = py$X30_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 30\")\n\np40 &lt;- ggplot(data = py$X40_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 40\")\n\np50 &lt;- ggplot(data = py$X50_df, aes(x = x, y = y, color = factor(py$Y))) +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"red\", \"darkgreen\"), \n                     name = \"Conversion Attempted\",\n                     labels = c(\"No\", \"Yes\")) +\n  labs(x = \"x\", y = \"y\") +\n  theme_minimal() +\n  ggtitle(\"Perplexity = 50\")\n\n\n\nPerplexity = 5Perplexity = 10Perplexity = 20Perplexity = 30Perplexity = 40Perplexity = 50\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPerplexity levels 20 and 30 seem to do the best job at reducing the dimensions so that similar points are grouped together, as there are clearer areas of green within the larger areas of red. However, going forward I would prefer to use PCA as my chosen method of dimensionality reduction due to the clearer distinction drawn between the two types of points. PCA seems to preserve data structure and information better than t-SNE because of this difference. The visualization capabilities are similar between the two, though it was easier to make a distinction between points in this case, as I only have two categories of points I am looking at. This may be a place that PCA outperforms t-SNE, as there are only two types of points. If there were multiple scenarios being looked at, then t-SNE may perform better. This is worth keeping in mind going forward as there are instances where there are many categories of points that could be looked at."
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "Link to GitHub repository"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Thomas Sigall is a graduate student at Georgetown University currently pursuing a Masters of Science in Data Science and Analytics. He graduated from Villanova University in 2023 with a B.A. in Philosophy and Minors in Computer Science and Statistics. Originally from Redmond, Washington, he enjoys studying a wide range of topics, as evidenced by his diverse academic background. Outside of academics, he enjoys running and loves to follow sports.\nLinkedIn: https://www.linkedin.com/in/thomas-sigall-496544224/\nGitHub: https://github.com/tsigall/"
  },
  {
    "objectID": "effect_on_coach_success.html",
    "href": "effect_on_coach_success.html",
    "title": "Effect on Coach Success",
    "section": "",
    "text": "Inputs and Setup\nlibrary(nflverse)\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(grid)\nlibrary(reticulate)\nlibrary(kableExtra)\nlibrary(gridExtra)\nlibrary(plotly)\nlibrary(RColorBrewer)\nlibrary(scales)\noptions(digits = 3)\n\nload(\"data/clean_data.Rdata\")\n\n\nAs we saw in the last step of our EDA, coaches are consistently far too conservative when it comes to fourth down decisions. We are trying to figure out why this may be the case. Two possible reasons immediately come to mind:\n\n4th down decisions have less effect on the outcome of games than we think.\nCoaches who are more conservative will keep their jobs longer, as being aggressive (and failing) on fourth down could be generally frowned upon by the NFL community.\n\n\nAll 4th Downs\nLets explore the first reason. One simple measure of coach success season by season is winning percentage. To take a quick look this, we can look at how correct decision rate on 4th down compares to the winning percentage a coach had in that particular season. Alongside this process we will also look at the average EPA per play on 4th downs coaches had in go-for-it situations that season. EPA is a measure of success that stands for “Estimated Points Added” and it measures the estimated points a play will add to the total final score at the end of the game.\n\n\nObtain Schedule Data\n# load in schedule data\nraw_games &lt;- nflreadr::load_schedules()\n\n# clean up home games\nhome_games &lt;- raw_games %&gt;%\n  filter(season &gt; 2015 & season &lt; 2023,\n         game_type == \"REG\") %&gt;%\n  dplyr::select(season,\n                result,\n                coach = home_coach) %&gt;%\n  dplyr::mutate(win = if_else(result &gt; 0, 1, 0),\n                loss = if_else(result &lt; 0, 1, 0),\n                tie = if_else(result == 0, 1, 0)) %&gt;%\n  dplyr::group_by(coach,\n                  season) %&gt;%\n  summarize(wins = sum(win),\n            losses = sum(loss),\n            ties = sum(tie))\n\n# clean up away games\naway_games &lt;- raw_games %&gt;%\n  filter(season &gt; 2015 & season &lt; 2023,\n         game_type == \"REG\") %&gt;%\n  dplyr::select(season,\n                result,\n                coach = away_coach) %&gt;%\n  dplyr::mutate(win = if_else(result &lt; 0, 1, 0),\n                loss = if_else(result &gt; 0, 1, 0),\n                tie = if_else(result == 0, 1, 0)) %&gt;%\n  dplyr::group_by(coach,\n                  season) %&gt;%\n  summarize(wins = sum(win),\n            losses = sum(loss),\n            ties = sum(tie))\n\n\n# combine away and home games by coach to get coaching records\ncoach_record &lt;- away_games %&gt;%\n  left_join(home_games, by = c(\"coach\", \"season\")) %&gt;%\n  mutate(wins = wins.x + wins.y,\n         losses = losses.x + losses.y,\n         ties = ties.x + ties.y) %&gt;%\n  select(coach, season, wins, losses, ties)\nrm(home_games, away_games, raw_games)\n\n# combine coaching records to fourth_decisions table\ncoaches &lt;- fourth_decisions %&gt;%\n  dplyr::select(coach, team = posteam, season, EPA) %&gt;%\n  left_join(coach_record, by = c(\"coach\", \"season\"))\n\n# add winning percentage to coaching table and select relevant columns\ncoaches &lt;- coaches %&gt;%\n  mutate(pct = (wins + ties * 0.5) / (wins + losses + ties)) %&gt;%\n  select(coach,\n         team,\n         season,\n         pct,\n         epa = EPA)\n\nwin_pct &lt;- coaches %&gt;%\n  left_join(fourth_decisions, by = c(\"coach\", \"team\" = \"posteam\", \"season\")) %&gt;%\n  select(coach,\n         team,\n         season,\n         correct_rate = should_go,\n         pct,\n         epa)\nkable(head(win_pct, 10))\n\n\n\n\n\ncoach\nteam\nseason\ncorrect_rate\npct\nepa\n\n\n\n\nAdam Gase\nMIA\n2016\n0.075\n0.625\n-0.278\n\n\nAdam Gase\nMIA\n2017\n0.375\n0.375\n-0.133\n\n\nAdam Gase\nMIA\n2018\n0.211\n0.438\n-0.021\n\n\nAdam Gase\nNYJ\n2019\n0.340\n0.438\n-0.171\n\n\nAdam Gase\nNYJ\n2020\n0.237\n0.125\n-0.382\n\n\nAndy Reid\nKC\n2016\n0.269\n0.750\n0.230\n\n\nAndy Reid\nKC\n2017\n0.170\n0.625\n0.096\n\n\nAndy Reid\nKC\n2018\n0.422\n0.750\n0.353\n\n\nAndy Reid\nKC\n2019\n0.286\n0.750\n0.021\n\n\nAndy Reid\nKC\n2020\n0.360\n0.875\n0.097\n\n\n\n\n\n\n\nNow we have the winning percentage and epa alongside the correct decision rate on fourth down for every coach by season. Let’s take a closer look at this table and normalize winning percentage, correct decision rate, and epa.\n\n\nCode\nwin_pct &lt;- win_pct %&gt;%\n  mutate(z_wins = as.numeric(scale(pct)),\n         z_correct = as.numeric(scale(correct_rate)),\n         z_epa = as.numeric(scale(epa)),\n         above_mean_wins = if_else(z_wins &gt; 0, 1, 0),\n         above_mean_correct = if_else(z_correct &gt; 0, 1, 0),\n         above_mean_epa = if_else(z_epa &gt; 0, 1, 0))\n\nkable(head(win_pct, 10))\n\n\n\n\n\ncoach\nteam\nseason\ncorrect_rate\npct\nepa\nz_wins\nz_correct\nz_epa\nabove_mean_wins\nabove_mean_correct\nabove_mean_epa\n\n\n\n\nAdam Gase\nMIA\n2016\n0.075\n0.625\n-0.278\n0.657\n-2.428\n-1.450\n1\n0\n0\n\n\nAdam Gase\nMIA\n2017\n0.375\n0.375\n-0.133\n-0.653\n0.567\n-0.613\n0\n1\n0\n\n\nAdam Gase\nMIA\n2018\n0.211\n0.438\n-0.021\n-0.326\n-1.075\n0.032\n0\n0\n1\n\n\nAdam Gase\nNYJ\n2019\n0.340\n0.438\n-0.171\n-0.326\n0.218\n-0.837\n0\n1\n0\n\n\nAdam Gase\nNYJ\n2020\n0.237\n0.125\n-0.382\n-1.963\n-0.808\n-2.054\n0\n0\n0\n\n\nAndy Reid\nKC\n2016\n0.269\n0.750\n0.230\n1.312\n-0.489\n1.482\n1\n0\n1\n\n\nAndy Reid\nKC\n2017\n0.170\n0.625\n0.096\n0.657\n-1.481\n0.705\n1\n0\n1\n\n\nAndy Reid\nKC\n2018\n0.422\n0.750\n0.353\n1.312\n1.039\n2.189\n1\n1\n1\n\n\nAndy Reid\nKC\n2019\n0.286\n0.750\n0.021\n1.312\n-0.324\n0.274\n1\n0\n1\n\n\nAndy Reid\nKC\n2020\n0.360\n0.875\n0.097\n1.967\n0.417\n0.710\n1\n1\n1\n\n\n\n\n\n\n\nNow we can cross tabulate effectively.\n\n\nCode\ncross_tab1 &lt;- as.data.frame(table(win_pct$above_mean_wins,\n                                 win_pct$above_mean_correct)) %&gt;%\n  rename(above_mean_wins = Var1,\n         above_mean_correct = Var2)\n\ncross_tab2 &lt;- as.data.frame(table(win_pct$above_mean_epa,\n                                 win_pct$above_mean_correct)) %&gt;%\n  rename(above_mean_epa = Var1,\n         above_mean_correct = Var2)\n\n# plot 1\nggplot(cross_tab1, aes(x = above_mean_correct, y = Freq, fill = factor(above_mean_wins))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Above Mean Correct Decision Rate on 4th Down\", \n       y = \"Frequency\",\n       fill = \"Above Mean 4th Down Wins\") +\n  scale_fill_manual(values = c(\"0\" = \"orange\", \"1\" = \"blue\"), labels = c(\"False\", \"True\")) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nCode\n# plot 2\nggplot(cross_tab2, aes(x = above_mean_correct, y = Freq, fill = factor(above_mean_epa))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Above Mean Correct Decision Rate on 4th Down\", \n       y = \"Frequency\",\n       fill = \"Above Mean 4th Down EPA\") +\n  scale_fill_manual(values = c(\"0\" = \"orange\", \"1\" = \"blue\"), labels = c(\"False\", \"True\")) +\n  theme(legend.position = \"top\")\n\n\n\n\n\n\nIt looks as if decision rate on 4th down has little effect on the win rate of coaches, which makes sense as when looking at plays across an entire game, 4th down plays make up a small percentage of those plays. It would be worth looking at how influential 4th down plays are on the result of each game compared to other types of plays, though.\nHaving a good correct 4th down decision does seem to have more of an effect on EPA, however. This makes sense as EPA in this case is estimated points added on 4th down, meaning this metric is directly measuring success on 4th down only, rather than success across an entire game. It is not surprising that having a good correct 4th down decision rate would lead to a more positive 4th down success metric than a whole game success metric.\nIt is an encouraging sign to see that making “correct” decisions on 4th down leads to more points on those 4th down plays. This means it would be useful to explore how 4th down plays contribute to a team’s final score compared to plays on other downs. This may give us a better idea as to how these 4th down decisions affect the success of coaches across the entire game, rather than simply on 4th down.\n\n\nHigh-Leverage Scenarios\nLet’s go back to our discussion involving high-leverage scenarios. What would happen if we did the same cross tabulation as above but only including high-leverage scenarios? In theory, this would give tell us more about a coaches success because these situations are single plays in which games are won and lost.\nHere are the first few rows of the dataset showing high-leverage situations we were looking at earlier. This time though it is a larger dataset because I chose to remove the condition that wp_succeed &gt; 0.95 as that limited us too much. Now the definition for a “high-leverage scenario” is one in which the difference in win probability between failing and succeeding in a 4th down attempt is 10%. This way we have 3,676 4th down situations to look at instead of only 113.\n\n\nCode\nleverage &lt;- fourth_downs %&gt;% \n  mutate(wp_change = wp_succeed - wp_fail,\n         coach = if_else(posteam_type == \"home\", home_coach, away_coach)) %&gt;%\n  select(season,\n         coach,\n         posteam,\n         defteam,\n         qtr,\n         time,\n         ydstogo,\n         yardline_100,\n         posteam_score,\n         defteam_score,\n         go_boost,\n         go,\n         epa,\n         wp,\n         wp_fail,\n         wp_succeed,\n         wp_change,\n         fg_make_prob,\n         miss_fg_wp,\n         make_fg_wp,\n         punt_wp) %&gt;%\n  filter(abs(wp_change) &gt; .1,\n         qtr == 4)\nkable(head(leverage))\n\n\n\n\n\nseason\ncoach\nposteam\ndefteam\nqtr\ntime\nydstogo\nyardline_100\nposteam_score\ndefteam_score\ngo_boost\ngo\nepa\nwp\nwp_fail\nwp_succeed\nwp_change\nfg_make_prob\nmiss_fg_wp\nmake_fg_wp\npunt_wp\n\n\n\n\n2016\nRex Ryan\nBUF\nBAL\n4\n14:19\n1\n49\n7\n10\n9.71\n0\n-1.879\n0.335\n0.221\n0.437\n0.216\n0.000\n0.206\n0.408\n0.269\n\n\n2016\nJohn Harbaugh\nBAL\nBUF\n4\n12:59\n18\n78\n10\n7\n-10.09\n0\n0.465\n0.630\n0.515\n0.781\n0.265\n0.000\n0.481\n0.793\n0.643\n\n\n2016\nRex Ryan\nBUF\nBAL\n4\n11:46\n4\n59\n7\n10\n2.80\n0\n-0.668\n0.267\n0.201\n0.406\n0.205\n0.000\n0.187\n0.418\n0.269\n\n\n2016\nJohn Harbaugh\nBAL\nBUF\n4\n07:43\n14\n27\n10\n7\n-6.31\n0\n2.973\n0.804\n0.681\n0.899\n0.218\n0.765\n0.656\n0.820\nNA\n\n\n2016\nJohn Harbaugh\nBAL\nBUF\n4\n05:42\n16\n19\n10\n7\n-7.08\n0\n0.469\n0.846\n0.733\n0.936\n0.203\n0.892\n0.706\n0.837\nNA\n\n\n2016\nRex Ryan\nBUF\nBAL\n4\n04:43\n18\n86\n7\n13\n-2.08\n0\n0.012\n0.101\n0.047\n0.204\n0.156\n0.000\n0.041\n0.196\n0.083\n\n\n\n\n\n\n\nApplying the same transformations to this smaller set as we did to the set of every 4th down play gives us performance by coach in these scenarios.\n\n\nCode\nleverage_decisions &lt;- leverage %&gt;%\n    mutate(should_go = ifelse((go_boost &gt; 0),\n                             (if_else(go == 100, 1, 0)),\n                             NA),\n          shouldnt_go = ifelse((go_boost &lt; 0),\n                             (if_else(go == 0, 1, 0)),\n                             NA)) %&gt;%\n    select(season, coach, posteam, ydstogo, yardline_100, go_boost, should_go, shouldnt_go, go, epa) %&gt;%\n    group_by(coach, posteam, season) %&gt;%\n    summarize(should_go = \n                sum(should_go == 1, na.rm = TRUE) / \n                (sum(should_go == 0 | should_go == 1, na.rm = TRUE)),\n              shouldnt_go = \n                sum(shouldnt_go == 1, na.rm = TRUE) / \n                (sum(shouldnt_go == 0 | shouldnt_go == 1, na.rm = TRUE)),\n              EPA = mean(epa),\n              count = n()) %&gt;%\n  filter(count &gt; 5) %&gt;%\n  ungroup()\n\ncoaches &lt;- fourth_decisions %&gt;%\n  dplyr::select(coach, team = posteam, season, EPA) %&gt;%\n  left_join(coach_record, by = c(\"coach\", \"season\")) %&gt;%\n  mutate(pct = (wins + ties * 0.5) / (wins + losses + ties)) %&gt;%\n  select(coach,\n         team,\n         season,\n         pct,\n         epa = EPA) %&gt;%\n  group_by(coach, team, season) %&gt;%\n  summarise(pct = mean(pct, na.rm = TRUE),\n            epa = mean(epa, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n\nleverage_win_pct &lt;- coaches %&gt;%\n  inner_join(leverage_decisions, by = c(\"coach\", \"team\" = \"posteam\", \"season\")) %&gt;%\n  select(coach,\n         team,\n         season,\n         should_go,\n         shouldnt_go,\n         pct,\n         epa, count)\nkable(head(leverage_win_pct))\n\n\n\n\n\ncoach\nteam\nseason\nshould_go\nshouldnt_go\npct\nepa\ncount\n\n\n\n\nAdam Gase\nMIA\n2016\n0.000\n1\n0.625\n-0.278\n16\n\n\nAdam Gase\nMIA\n2017\n0.500\n1\n0.375\n-0.133\n14\n\n\nAdam Gase\nMIA\n2018\n0.000\n1\n0.438\n-0.021\n13\n\n\nAdam Gase\nNYJ\n2019\n0.286\n1\n0.438\n-0.171\n17\n\n\nAdam Gase\nNYJ\n2020\n0.400\n1\n0.125\n-0.382\n15\n\n\nAndy Reid\nKC\n2016\n0.250\n1\n0.750\n0.230\n19\n\n\n\n\n\n\n\nNow we can cross tabulate as before.\n\n\nCode\nleverage_win_pct &lt;- leverage_win_pct %&gt;%\n  mutate(z_wins = as.numeric(scale(pct)),\n         z_should = as.numeric(scale(should_go)),\n         z_shouldnt = as.numeric(scale(shouldnt_go)),\n         z_epa = as.numeric(scale(epa)),\n         above_mean_wins = if_else(z_wins &gt; 0, 1, 0),\n         above_mean_should = if_else(z_should &gt; 0, 1, 0),\n         above_mean_shouldnt = if_else(z_shouldnt &gt; 0, 1, 0),\n         above_mean_epa = if_else(z_epa &gt; 0, 1, 0))\n\nkable(head(leverage_win_pct, 10))\n\n\n\n\n\ncoach\nteam\nseason\nshould_go\nshouldnt_go\npct\nepa\ncount\nz_wins\nz_should\nz_shouldnt\nz_epa\nabove_mean_wins\nabove_mean_should\nabove_mean_shouldnt\nabove_mean_epa\n\n\n\n\nAdam Gase\nMIA\n2016\n0.000\n1.000\n0.625\n-0.278\n16\n0.652\n-1.801\n0.493\n-1.445\n1\n0\n1\n0\n\n\nAdam Gase\nMIA\n2017\n0.500\n1.000\n0.375\n-0.133\n14\n-0.655\n0.438\n0.493\n-0.612\n0\n1\n1\n0\n\n\nAdam Gase\nMIA\n2018\n0.000\n1.000\n0.438\n-0.021\n13\n-0.328\n-1.801\n0.493\n0.031\n0\n0\n1\n1\n\n\nAdam Gase\nNYJ\n2019\n0.286\n1.000\n0.438\n-0.171\n17\n-0.328\n-0.522\n0.493\n-0.834\n0\n0\n1\n0\n\n\nAdam Gase\nNYJ\n2020\n0.400\n1.000\n0.125\n-0.382\n15\n-1.961\n-0.010\n0.493\n-2.047\n0\n0\n1\n0\n\n\nAndy Reid\nKC\n2016\n0.250\n1.000\n0.750\n0.230\n19\n1.305\n-0.682\n0.493\n1.474\n1\n0\n1\n1\n\n\nAndy Reid\nKC\n2017\n0.333\n0.857\n0.625\n0.096\n22\n0.652\n-0.308\n-1.540\n0.700\n1\n0\n0\n1\n\n\nAndy Reid\nKC\n2018\n0.750\n1.000\n0.750\n0.353\n16\n1.305\n1.558\n0.493\n2.178\n1\n1\n1\n1\n\n\nAndy Reid\nKC\n2019\n0.400\n0.909\n0.750\n0.021\n16\n1.305\n-0.010\n-0.801\n0.271\n1\n0\n0\n1\n\n\nAndy Reid\nKC\n2020\n0.500\n1.000\n0.875\n0.097\n11\n1.958\n0.438\n0.493\n0.706\n1\n1\n1\n1\n\n\n\n\n\n\n\n\n\nCode\ncross_tab1 &lt;- as.data.frame(table(leverage_win_pct$above_mean_wins,\n                                 leverage_win_pct$above_mean_should)) %&gt;%\n  rename(above_mean_wins = Var1,\n         above_mean_should = Var2)\n\ncross_tab2 &lt;- as.data.frame(table(leverage_win_pct$above_mean_epa,\n                                 leverage_win_pct$above_mean_should)) %&gt;%\n  rename(above_mean_epa = Var1,\n         above_mean_should = Var2)\n\n# plot 1\nggplot(cross_tab1, aes(x = above_mean_should, y = Freq, fill = factor(above_mean_wins))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Above Mean Correct Decision Rate on 4th Down (Go for it scenarios)\", \n       y = \"Frequency\",\n       fill = \"Above Mean Wins\") +\n  scale_fill_manual(values = c(\"0\" = \"orange\", \"1\" = \"blue\"), labels = c(\"False\", \"True\")) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nCode\n# plot 2\nggplot(cross_tab2, aes(x = above_mean_should, y = Freq, fill = factor(above_mean_epa))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Above Mean Correct Decision Rate on 4th Down (Go for it scenarios)\", \n       y = \"Frequency\",\n       fill = \"Above Mean 4th Down EPA\") +\n  scale_fill_manual(values = c(\"0\" = \"orange\", \"1\" = \"blue\"), labels = c(\"False\", \"True\")) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nWe see similar results here, where 4th down correct decision rate does not have much of an effect on a team’s record throughout the entire season, but there seems to be even more of an effect on 4th down EPA.\n\n\nExport Data\nsave(leverage_win_pct, file = \"data/leverage_win_pct.Rdata\")\nwrite_csv(leverage_win_pct, \"data/leverage_win_pct.csv\")"
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "Conclusions",
    "section": "",
    "text": "Throughout this project we have looked at a variety of ways to analyze one of the most important decisions in sports: the 4th down conversion. From data visualizations, to classification, to clustering, we have evaluated this singular decision from many angles. However, after studying this process for many months, I have found the most useful way to look at this decision through, fittingly, the deicion tree. It most closely models the actual decision making process coaches go through when on the sideline, and the tools available to us through packages in R and Python allow us to easily build these trees specific to individual coaches and analyze their components to determine exactly how these coaches make their decisions.\nThe most useful plot I encoutered throughout this project was the feature importance plot. This can be generated directly from a decision tree and, as explained earlier, gives us a way to determine what coaches “care” about when making a decision. This simple plot gives us a powerful and unique look inside a coach’s mind, giving us information that the coach themselves may not even be aware of. Often, given the nature of these high-pressure, fleeting situations, coaches make split-second, gut decisions. They have been making decisions like this all their lives and may not stop and take the time to think through their choices. However, even though this decion happens so quickly, it still does happen in the form of a decision tree, at its most basic level.\nCoaches make these decisions by asking questions about their situation. What is the score? How much time is left? Where are we on the field? The answers to these numerous questions inform their eventual, binary decision: will they go for it? The first question they ask is the most important, as the answer to that question determines their next question, and the next question after that. Working our way down that tree of questions, that tree of decisions, gives us valuable information about a coach’s thought process. We can then determine the importance of each variable coaches consider when making these decisions, giving us a way to comapre how they approach the game.\nThe most valuable insight I gained throughout this project can be displayed in two of these feature importance plots. Below is a plot gained from looking at the decisions made on fourth down by all coaches in the NFL over the past 7 seasons. Out of these five readily available variables, which ones do coaches care about the most?\n\nThe results showed that there was a fairly clear hierarchy, and seemed to make sense, at least for someone who has watched a lot of football. All five variables were represented, and all had a decently large importance. Yards to go was clearly the most important. Yardline and score were next most important, being about 60% as important as yards to go. The two time variables were the least important, but still 20% as important as yards to go.\nI wanted to compare this plot generated from actual decisions made to a plot generated from the optimal decisions made. Take a hypothetical coach making the “correct” decision every time (at least going for it when doing so would increase your win probability and not going for it when it would not). What would a coach like that care about?\n\nThat plot can be seen above. One big difference immediately jumps out, that being the remarkable decrease in importance of all variables other than yards to go. That variable dominates this plot, with the other four varibales all being less than 25% as important. This tells us that when making a fourth down decion, the optimal coach makes it almost entirely based on how many yards they need to gain to get the first down. Maybe your team is winning by a lot then it is not worth the risk, hence the importance of the score. But the overwhelming importance of yards to go when compared to the other variables shows us that these decisions may be simpler than we think.\nFor all the discussion around these decisions, the fact that only one variable seems to be significantly important is very interesting. These seemingly complicated decions could possibly be simplified by asking only one question: how many yards do I need to gain to pick up a first down? Looking at the charts generated from the decisions of some of the best coaches on fourth down in the league, we can see a similar pattern emerge.\n\nThis plot was generated using fourth down decisions made by Kevin Stefanski, the coach of the Cleveland Browns and one of the best coaches on fourth down over the past few years. His plot looks remarkably similar to the optimal plot, with yards to go clearly his most important variable (though interestingly yardline and score were flipped and had each had more importance for Stefanski). We discussed the difference between young and old coaches further in the decision trees section, but that trend continued to the extreme there with the time variables not even appearing on Brandon Staley’s and Nick Sirianni’s charts, two young NFL coaches. This may mean the league is catching on to the simplicity of this decision, and younger coaches who are more receptive to change are simplifying it already. Regardless, the importance of yards to go and relative unimportance of the other four variables was the most important conclusion I reached in this project and something that I find fascinating. We may be able to simplify one of the most important and polarizing decisions in all of sports to looking at just a few factors, or maybe even just one.\n\nFuture Steps\nAs with any good project however, at the end I am almost left with more questions than answers. The natrual next step to this analysis is to fully understand the effect making good decisions on fourth downs has on games. This was briefly touched on in the Naïve Bayes section, but fourth down decisions are a relatively small part of football. It is only 1 of 4 downs after all, so it is possible that there really is not much advatage to be gained. I do think that these plays are some of the most important plays in a game, however, so their effect on the overall result is worth studying.\nFinally, I would also like to continue by looking at how accurate we can make our fourth down decisions. These decision trees are fairly simple models and as mentioned earlier in our high-leverage scenario analysis, some fourh down decisions are easier to predict than others. I think this project naturally lends itself into using more advanced models to make these descisions, such as artifical neural networks. We are modeling the decision process of real coaches after all.\nFinally, I would like to determine what the correct play call to make on fourth down would be. Despite all this analysis, determining whether or not to go for it on fourth down is only the first step. After deciding to go for it, a coach must determine what play they want to call, a much more daunting task. While this would be an incredibly difficult pursuit, is is nevertheless a worthwhile one.\nThese three possible extensions are just a few examples of how this could be taken further. The appeal of sports, and the NFL in particular, is there is seemingly no end to how deep down the rabbit hole one can go. When we inevitably determine the precisely correct decision to make on fourth down, opposing coaches will then know what is coming. The correct decisions become incorrect decisions, and our analysis must repeat itself yet again. Some may see this endless cycle as a futile one, but others relish this challenge and are excited by the new possibilities that are opening up as a result of the constant innovation within the game. Regardless, many more fourth down decisions are yet to be made, and I am incredibly excited to see how this deep and complex game conintues to evolve."
  },
  {
    "objectID": "decision_trees_r.html",
    "href": "decision_trees_r.html",
    "title": "Decision Trees in R",
    "section": "",
    "text": "df &lt;- read.csv(\"data/dt.csv\")[,-1]"
  },
  {
    "objectID": "decision_trees_r.html#tree-1",
    "href": "decision_trees_r.html#tree-1",
    "title": "Decision Trees in R",
    "section": "Tree 1",
    "text": "Tree 1\n\n# Only using readily available information (field position, time left, score, etc.)\ndf1 &lt;- df[,c(2, 3, 4, 5, 13, 14)]\ntree &lt;- make_tree(df1)"
  },
  {
    "objectID": "decision_trees_r.html#tree-2",
    "href": "decision_trees_r.html#tree-2",
    "title": "Decision Trees in R",
    "section": "Tree 2",
    "text": "Tree 2\n\n# Also using win probability information\ndf2 &lt;- df[,2:14]\ntree &lt;- make_tree(df2)"
  },
  {
    "objectID": "decision_trees_r.html#tree-3",
    "href": "decision_trees_r.html#tree-3",
    "title": "Decision Trees in R",
    "section": "Tree 3",
    "text": "Tree 3\n\n# High leverage situations\nleverage &lt;- df %&gt;%\n  filter(abs(wp_succeed - wp_fail) &gt; .1,\n         game_half == 2)\n\ndf3 &lt;- leverage[,c(2, 3, 4, 5, 13, 14)]\ntree &lt;- make_tree(df3)"
  },
  {
    "objectID": "data_cleaning2.html",
    "href": "data_cleaning2.html",
    "title": "Text Data",
    "section": "",
    "text": "Sentiment Analysis\nThe NFL subreddit is a useful place to extract text data produced by fans and their reaction to these essential decisions. Like most jobs, the goal of an NFL head coach is not only to win games, but to keep their bosses happy. The size and outspoken nature of NFL fan bases can be a factor in the job security of these coaches, as if a coach loses the fans, their job gets a lot harder. This is where sentiment analysis comes in, as getting an idea of how fans feel about 4th down decisions by certain coaches may give us insights into how they are making their decisions, and whether or not the fans have any influence on the decision making process.\nThis allows us to get posts from the NFL subreddit using a search query of “4th down” and access the comments of those posts.\n\n# subreddit = reddit.subreddit(\"nfl\")\n# query = \"4th down\"\n# \n# top_posts = subreddit.search(query, limit=100)\n# urls = []\n# corpus = []\n# \n# for post in top_posts:\n#     urls.append(post.permalink)\n#     \n# url = \"https://www.reddit.com\" + urls[0]\n# \n# submission = reddit.submission(url=url)\n# \n# submission.comments.replace_more(limit=0)\n# for top_level_comment in submission.comments:\n#     corpus.append(top_level_comment.body)\n# urls\n\nThe overall sentiment from this brief analysis is a positive one, but the search terms need to be more specific to get any useful information out of this process.\n\n# from nltk.sentiment import SentimentIntensityAnalyzer\n# \n# overall = []\n# sia = SentimentIntensityAnalyzer()\n# \n# for text in corpus:\n#   score=sia.polarity_scores(text)\n#   overall.append(score['compound'])\n# \n# corpus[1]"
  },
  {
    "objectID": "decision_trees.html",
    "href": "decision_trees.html",
    "title": "Decision Trees",
    "section": "",
    "text": "The end goal of making these decision trees is to model the decision making process for each coach. To help us better understand the individual trees, we will start by making an “average” baseline tree that is built using data from every coach. This classification tree will predict whether or not a coach decides to go for it on a given 4th down scenario. It may help to try this using every 4th down play, as well as with some filters imposed on the data to extract more informative, higher leverage scenarios.\nImports\nimport pandas as pd\nimport seaborn as sns \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay\nfrom yellowbrick.model_selection import FeatureImportances"
  },
  {
    "objectID": "decision_trees.html#max_depth",
    "href": "decision_trees.html#max_depth",
    "title": "Decision Trees",
    "section": "max_depth",
    "text": "max_depth\n\n\nmax_depth Tuning\ntest_results=[]\ntrain_results=[]\n\nfor num_layer in range(1,10):\n    model = tree.DecisionTreeClassifier(max_depth=num_layer)\n    model = model.fit(x_train, y_train)\n\n    yp_train=model.predict(x_train)\n    yp_test=model.predict(x_test)\n\n    # print(y_pred.shape)\n    test_results.append([num_layer,\n    accuracy_score(y_test, yp_test),\n    recall_score(y_test, yp_test,pos_label=0),\n    recall_score(y_test, yp_test,pos_label=1)])\n    \n    train_results.append([num_layer,\n    accuracy_score(y_train, yp_train),\n    recall_score(y_train, yp_train,pos_label=0),\n    recall_score(y_train, yp_train,pos_label=1)])\n\n\n\n\nmax_depth Plots\nplt.cla()\nax = sns.lineplot(x=np.asarray(test_results)[:,0],\n                y=np.asarray(test_results)[:,1],\n                color=\"red\",\n                marker=\"o\",\n                label=\"test\")\nsns.lineplot(x=np.asarray(train_results)[:,0],\n                y=np.asarray(train_results)[:,1],\n                color=\"blue\",\n                marker=\"o\",\n                label=\"train\")\nax.set(xlabel=\"Number of layers in the decision tree (max_depth)\", ylabel=\"ACCURACY\")\nplt.legend()\nplt.show()\n\nplt.cla()\nax = sns.lineplot(x=np.asarray(test_results)[:,0],\n                y=np.asarray(test_results)[:,3],\n                color=\"red\",\n                marker=\"o\",\n                label=\"test\")\nsns.lineplot(x=np.asarray(train_results)[:,0],\n                y=np.asarray(train_results)[:,3],\n                color=\"blue\",\n                marker=\"o\",\n                label=\"train\")\nax.set(xlabel=\"Number of layers in the decision tree (max_depth)\", ylabel=\"POSITIVE RECALL (Y=1)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n6 layers is the optimal max_depth parameter."
  },
  {
    "objectID": "decision_trees.html#min_samples_leaf",
    "href": "decision_trees.html#min_samples_leaf",
    "title": "Decision Trees",
    "section": "min_samples_leaf",
    "text": "min_samples_leaf\n\n\nmin_samples Tuning\ntest_results=[]\ntrain_results=[]\n\nfor samples in range(1,1000):\n    model = tree.DecisionTreeClassifier(max_depth=6, min_samples_leaf = samples)\n    model = model.fit(x_train, y_train)\n\n    yp_train=model.predict(x_train)\n    yp_test=model.predict(x_test)\n\n    # print(y_pred.shape)\n    test_results.append([samples,\n    accuracy_score(y_test, yp_test),\n    recall_score(y_test, yp_test,pos_label=0),\n    recall_score(y_test, yp_test,pos_label=1)])\n    \n    train_results.append([samples,\n    accuracy_score(y_train, yp_train),\n    recall_score(y_train, yp_train,pos_label=0),\n    recall_score(y_train, yp_train,pos_label=1)])\n\n\n\n\nmin_samples Plots\nplt.cla()\nax = sns.lineplot(x=np.asarray(test_results)[:,0],\n                y=np.asarray(test_results)[:,1],\n                color=\"red\",\n                marker=\"o\",\n                label=\"test\")\nsns.lineplot(x=np.asarray(train_results)[:,0],\n                y=np.asarray(train_results)[:,1],\n                color=\"blue\",\n                marker=\"o\",\n                label=\"train\")\nax.set(xlabel=\"Minimum samples in leaves(min_samples_leaf)\", ylabel=\"ACCURACY\")\nplt.legend()\nplt.show()\n\nplt.cla()\nax = sns.lineplot(x=np.asarray(test_results)[:,0],\n                y=np.asarray(test_results)[:,3],\n                color=\"red\",\n                marker=\"o\",\n                label=\"test\")\nsns.lineplot(x=np.asarray(train_results)[:,0],\n                y=np.asarray(train_results)[:,3],\n                color=\"blue\",\n                marker=\"o\",\n                label=\"train\")\nax.set(xlabel=\"Minimum samples in leaves(min_samples_leaf)\", ylabel=\"POSITIVE RECALL (Y=1)\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nAround 175 samples is a good minimum for min_samples_leaf."
  },
  {
    "objectID": "decision_trees.html#visualize-best-tree",
    "href": "decision_trees.html#visualize-best-tree",
    "title": "Decision Trees",
    "section": "Visualize Best Tree",
    "text": "Visualize Best Tree\n\n\nCode\nbest_clf = tree.DecisionTreeClassifier(random_state = 621, max_depth = 6, min_samples_leaf = 175)\nbest_model = best_clf.fit(x_train.values, y_train)\n\nfig = plt.figure(figsize=(30,20))\n_ = tree.plot_tree(best_model,\n                feature_names=X.columns,\n                class_names=[str(class_) for class_ in Y.unique()], \n                filled=True,\n                fontsize = 6.5)\nplt.show()\n\n\n\n\n\nIncreasing max_depth made this tree larger and therefore harder to visualize. Let’s run through the scenario we looked at previously and see what changes with this new, optimized tree.\n\n\nNodes\nviz_model = dtreeviz.model(best_clf,\n                           X_train=x_train, y_train=y_train,\n                           feature_names=[\"game_half\", \"half_seconds_remaining\", \"ydstogo\", \"yardline_100\", \"score_diff\"],\n                           target_name=\"go\", class_names=[0, 1])\nviz_model.view(x=instance, show_just_path=True, orientation = \"LR\", colors = {'classes': colors})\n\n\n\n\n\n\n\nFeatures\nviz_model.instance_feature_importance(x = instance, figsize=(3.5,2))\n\n\n\n\n\nThe main difference here is that game_half played a role in making this decision, even more so than half_seconds_remaining, which is interesting considering that it did not come into play in the previous scenario. In this tree, this situaion finds itself in a leaf where even more scenarios resulted in the coach not going for it.\nOptimized tree metrics:\n\n\nCode\nyp_train = best_model.predict(x_train.values)\nyp_test = best_model.predict(x_test.values)\n\nconfusion_plot(y_test, yp_test)\n\n\nACCURACY:  0.902\nNEGATIVE RECALL (Y=0):  0.945\nNEGATIVE PRECISION (Y=0):  0.938\nPOSITIVE RECALL (Y=1):  0.684\nPOSITIVE PRECISION (Y=1):  0.711\n[[4408  255]\n [ 289  627]]"
  },
  {
    "objectID": "decision_trees.html#all-coaches",
    "href": "decision_trees.html#all-coaches",
    "title": "Decision Trees",
    "section": "All Coaches",
    "text": "All Coaches\n\n\nCode\nall_tree = make_tree(df, show_features=True)"
  },
  {
    "objectID": "decision_trees.html#brandon-staley",
    "href": "decision_trees.html#brandon-staley",
    "title": "Decision Trees",
    "section": "Brandon Staley",
    "text": "Brandon Staley\n\n\nCode\nstaley = df_all[df_all[\"coach\"] == \"Brandon Staley\"]\nstaley_tree = make_tree(staley, show_features=True)"
  },
  {
    "objectID": "decision_trees.html#bill-belichick",
    "href": "decision_trees.html#bill-belichick",
    "title": "Decision Trees",
    "section": "Bill Belichick",
    "text": "Bill Belichick\n\n\nCode\nbelichick = df_all[df_all[\"coach\"] == \"Bill Belichick\"]\nbelichick_tree = make_tree(belichick, show_features=True)"
  },
  {
    "objectID": "decision_trees.html#pete-carroll",
    "href": "decision_trees.html#pete-carroll",
    "title": "Decision Trees",
    "section": "Pete Carroll",
    "text": "Pete Carroll\n\n\nCode\ncarroll = df_all[df_all[\"coach\"] == \"Pete Carroll\"]\ncarroll_tree = make_tree(carroll, show_features=True)"
  },
  {
    "objectID": "decision_trees.html#nick-sirianni",
    "href": "decision_trees.html#nick-sirianni",
    "title": "Decision Trees",
    "section": "Nick Sirianni",
    "text": "Nick Sirianni\n\n\nCode\nsirianni = df_all[df_all[\"coach\"] == \"Nick Sirianni\"]\nsirianni_tree = make_tree(sirianni, show_features=True)\n\n\n\n\n\nSomething that immediately sticks out to me is the difference between young and old head coaches. Staley and Sirianni are young head coaches, while Belichick and Carroll are the two oldest head coaches in the NFL. It looks like, according to these feature importance charts, older coaches take a more balanced approach when making their fouth down decisions, at least considering all five variables. Younger coaches do not even consider the game half, or the time remaining. The older coaches match the overall feature importance much more closely than the younger coaches. Looking at this feature importance chart is incredibly interesting, and given the time (and space on this page) I would make charts for all 32 head coaches. However, I think these four give us a relatively good idea of what the league looks like in terms of what they look for when making these deicsions."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "A significant source of data was obtained using the nflreadr package. More information can be found here: Ho and Carl (2023).\n\n\n\n\nReferences\n\nHo, Tan, and Sebastian Carl. 2023. Nflreadr: Download ’Nflverse’ Data."
  }
]