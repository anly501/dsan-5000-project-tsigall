clf = tree.DecisionTreeClassifier(random_state = 621, max_depth = 5)
clf = tree.DecisionTreeClassifier(random_state = 621, max_depth = 5)
clf.fit(x_train, y_train)
class_names=[str(class_) for class_ in Y.unique()])
viz = dtreeviz.model(clf,
X_train = x_train, y_train = y_train,
target_name="go",
feature_names=list(X.columns),
class_names=[str(class_) for class_ in Y.unique()])
features = ['game_half', 'half_seconds_remaining', 'ydstogo', 'yardline_100', 'score_diff']
target = "go"
clf = tree.DecisionTreeClassifier(random_state = 621, max_depth = 5)
clf.fit(x_train, y_train)
viz = dtreeviz.model(clf,
X_train = x_train, y_train = y_train,
target_name="go",
feature_names=list(X.columns),
class_names=[str(class_) for class_ in Y.unique()])
library(rpart)
library(plotly)
library(rattle)
library(tidyverse)
library(caret)
library(yardstick)
options(scipen = 999, digits = 3)
df <- read.csv("df.csv")[,-1]
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
View(df1)
View(df1)
View(df)
View(df)
df <- read.csv("df.csv")
View(df)
library(tidyverse)
load("raw_nfl.Rdata")
df <- raw_data %>%
filter(!is.na(go_boost) & !is.na(go)) %>%
select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)
df <- df %>%
mutate(coach = if_else(posteam_type == "home", home_coach, away_coach),
home_coach = coach,
score_diff = posteam_score - defteam_score,
go = if_else(go == 100, 1, 0),
game_half = if_else(game_half == "Half1", 1, 2)) %>%
select(-coach,
-away_coach,
-season,
-posteam,
-defteam,
-posteam_type,
-epa,
-punt_wp,
-posteam_score,
-defteam_score) %>%
rename(coach = home_coach) %>%
select(-go, everything())
write.csv(df, "df.csv")
df <- read.csv("df.csv")
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
View(df)
df <- read.csv("df.csv")[,-1]
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
write.csv(df, "dt.csv")
load("data/clean_data.Rdata")
# Chunk 1: setup
library(tidyverse)
library(plotly)
library(reticulate)
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: clean_data
load("data/clean_data.Rdata")
fourth_by_coach <- fourth_decisions %>%
group_by(coach) %>%
summarize(should_go = mean(should_go),
shouldnt_go = mean(shouldnt_go)) %>%
ungroup()
head(fourth_by_coach)
# Chunk 3: initial_viz
plot_ly(data = fourth_by_coach, x = ~should_go, y = ~shouldnt_go, type = "scatter", mode = "markers")
# Chunk 4: to_csv
write_csv(fourth_by_coach, file = "data/fourth_by_coach.csv")
# Chunk 5: imports
import pandas as pd
reticulate::repl_python()
library(rpart)
library(plotly)
library(rattle)
library(tidyverse)
library(caret)
library(yardstick)
options(scipen = 999, digits = 3)
df <- read.csv("data/df.csv")[,-1]
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
View(df1)
View(df)
df <- read.csv("data/df.csv")
View(df)
df <- read.csv("data/dt.csv")[,-1]
library(tidyverse)
load("data/raw_nfl.Rdata")
df <- raw_data %>%
filter(!is.na(go_boost) & !is.na(go)) %>%
select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)
df <- df %>%
mutate(coach = if_else(posteam_type == "home", home_coach, away_coach),
home_coach = coach,
score_diff = posteam_score - defteam_score,
go = if_else(go == 100, 1, 0),
game_half = if_else(game_half == "Half1", 1, 2)) %>%
select(-coach,
-away_coach,
-season,
-posteam,
-defteam,
-posteam_type,
-epa,
-punt_wp,
-posteam_score,
-defteam_score) %>%
rename(coach = home_coach) %>%
select(-go, everything())
write.csv(df, "data/dt.csv")
df <- read.csv("data/dt.csv")[,-1]
library(rpart)
library(plotly)
library(rattle)
library(tidyverse)
library(caret)
library(yardstick)
options(scipen = 999, digits = 3)
df <- read.csv("data/dt.csv")[,-1]
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
# Also using win probability information
df2 <- df[,2:14]
tree <- make_tree(df2)
# High leverage situations
leverage <- df %>%
filter(abs(wp_succeed - wp_fail) > .1,
game_half == 2)
df3 <- leverage[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df3)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
test_results <- data.frame()
train_results <- data.frame()
for (num_layer in 1:10) {
model <- rpart(y_train ~ ., data = cbind(x_train, y_train), method = "class", control = rpart.control(maxdepth = num_layer))
yp_train <- predict(model, newdata = x_train, type = "class")
yp_test <- predict(model, newdata = x_test, type = "class")
# Calculate metrics
test_metrics <- cbind(num_layer,
confusionMatrix(yp_test, as.factor(y_test))$overall[1],
confusionMatrix(yp_test, as.factor(y_test))$overall[2],
confusionMatrix(yp_test, as.factor(y_test))$overall[3],
confusionMatrix(yp_test, as.factor(y_test))$overall[4])
train_metrics <- cbind(num_layer,
confusionMatrix(yp_train, as.factor(y_train))$overall[1],
confusionMatrix(yp_train, as.factor(y_train))$overall[2],
confusionMatrix(yp_train, as.factor(y_train))$overall[3],
confusionMatrix(yp_train, as.factor(y_train))$overall[4])
test_results <- rbind(test_results, test_metrics)
train_results <- rbind(train_results, train_metrics)
}
# Rename columns for clarity
colnames(test_results) <- c("num_layer", "accuracy", "kappa", "Accuracy_0", "Accuracy_1")
rownames(test_results) <- NULL
colnames(train_results) <- c("num_layer", "accuracy", "kappa", "Accuracy_0", "Accuracy_1")
rownames(train_results) <- NULL
plot_ly(data = train_results, x = ~num_layer) %>%
add_trace(y = ~accuracy, name = "test", mode = "lines", type = "scatter") %>%
add_trace(y = ~test_results$accuracy, name = "train", mode = "lines", type = "scatter")
staley <- df %>%
filter(coach == "Brandon Staley")
staley1 <- staley[,c(2, 3, 4, 5, 13, 14)]
staley_tree <- make_tree(staley1, "Brandon Staley")
belichick <- df %>%
filter(coach == "Bill Belichick")
belichick1 <- belichick[,c(2, 3, 4, 5, 13, 14)]
belichick_tree <- make_tree(belichick1, "Bill Belichick")
carroll <- df %>%
filter(coach == "Pete Carroll")
carroll1 <- carroll[,c(2, 3, 4, 5, 13, 14)]
carroll_tree <- make_tree(carroll1)
sirianni <- df %>%
filter(coach == "Nick Sirianni")
sirianni1 <- sirianni[,c(2, 3, 4, 5, 13, 14)]
sirianni_tree <- make_tree(sirianni1)
mcvay <- df %>%
filter(coach == "Sean McVay")
mcvay_tree <- make_tree(mcvay[,c(2, 3, 4, 5, 13, 14)])
stefanski <- df %>%
filter(coach == "Kevin Stefanski")
stefanski_tree <- make_tree(stefanski[,c(2, 3, 4, 5, 13, 14)])
campbell <- df %>%
filter(coach == "Dan Campbell")
campbell_tree <- make_tree(campbell[,c(2, 3, 4, 5, 13, 14)], "Dan Campbell")
cpu <- df2 %>%
mutate(go = if_else(go_boost > 1, 1, 0))
cpu1 <- cpu[,c(1, 2, 3, 4, 12, 13)]
cpu_tree <- make_tree(cpu1)
library(reticulate)
use_condaenv("r-env")
reticulate::repl_python()
#| code-fold: true
#| code-summary: Imports
library(tidyverse)
library(kableExtra)
#| code-fold: true
load("data/raw_nfl.Rdata")
df <- raw_data %>%
filter(!is.na(go_boost) & !is.na(go)) %>%
select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)
df <- df %>%
mutate(coach = if_else(posteam_type == "home", home_coach, away_coach),
home_coach = coach,
score_diff = posteam_score - defteam_score,
go = if_else(go == 100, 1, 0),
game_half = if_else(game_half == "Half1", 1, 2)) %>%
select(-coach,
-away_coach,
-season,
-posteam,
-defteam,
-posteam_type,
-epa) %>%
rename(coach = home_coach) %>%
select(-go, everything())
kable(head(df))
write_csv(df, file = "data/df.csv")
#| code-fold: true
kable(head(df %>%
group_by(coach) %>%
summarize(count = n()) %>%
arrange(desc(count))))
reticulate::repl_python()
#| code-fold: true
#| code-summary: Imports
library(tidyverse)
library(kableExtra)
#| code-fold: true
load("data/raw_nfl.Rdata")
df <- raw_data %>%
filter(!is.na(go_boost) & !is.na(go)) %>%
select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)
df <- df %>%
mutate(coach = if_else(posteam_type == "home", home_coach, away_coach),
home_coach = coach,
score_diff = posteam_score - defteam_score,
go = if_else(go == 100, 1, 0),
game_half = if_else(game_half == "Half1", 1, 2)) %>%
select(-coach,
-away_coach,
-season,
-posteam,
-defteam,
-posteam_type,
-epa) %>%
rename(coach = home_coach) %>%
select(-go, everything())
kable(head(df))
write_csv(df, file = "data/df.csv")
#| code-fold: true
kable(head(df %>%
group_by(coach) %>%
summarize(count = n()) %>%
arrange(desc(count))))
reticulate::repl_python()
