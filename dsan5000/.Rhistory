clf = tree.DecisionTreeClassifier(random_state = 621, max_depth = 5)
clf = tree.DecisionTreeClassifier(random_state = 621, max_depth = 5)
clf.fit(x_train, y_train)
class_names=[str(class_) for class_ in Y.unique()])
viz = dtreeviz.model(clf,
X_train = x_train, y_train = y_train,
target_name="go",
feature_names=list(X.columns),
class_names=[str(class_) for class_ in Y.unique()])
features = ['game_half', 'half_seconds_remaining', 'ydstogo', 'yardline_100', 'score_diff']
target = "go"
clf = tree.DecisionTreeClassifier(random_state = 621, max_depth = 5)
clf.fit(x_train, y_train)
viz = dtreeviz.model(clf,
X_train = x_train, y_train = y_train,
target_name="go",
feature_names=list(X.columns),
class_names=[str(class_) for class_ in Y.unique()])
library(rpart)
library(plotly)
library(rattle)
library(tidyverse)
library(caret)
library(yardstick)
options(scipen = 999, digits = 3)
df <- read.csv("df.csv")[,-1]
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
View(df1)
View(df1)
View(df)
View(df)
df <- read.csv("df.csv")
View(df)
library(tidyverse)
load("raw_nfl.Rdata")
df <- raw_data %>%
filter(!is.na(go_boost) & !is.na(go)) %>%
select(season, home_coach, away_coach, posteam, defteam, posteam_type, game_half, half_seconds_remaining, ydstogo, yardline_100, posteam_score, defteam_score, posteam, go_boost, go, epa, wp_fail, wp_succeed, wp, fg_make_prob, miss_fg_wp, make_fg_wp, punt_wp)
df <- df %>%
mutate(coach = if_else(posteam_type == "home", home_coach, away_coach),
home_coach = coach,
score_diff = posteam_score - defteam_score,
go = if_else(go == 100, 1, 0),
game_half = if_else(game_half == "Half1", 1, 2)) %>%
select(-coach,
-away_coach,
-season,
-posteam,
-defteam,
-posteam_type,
-epa,
-punt_wp,
-posteam_score,
-defteam_score) %>%
rename(coach = home_coach) %>%
select(-go, everything())
write.csv(df, "df.csv")
df <- read.csv("df.csv")
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
View(df)
df <- read.csv("df.csv")[,-1]
make_tree <- function(df, caption = NULL, metrics = FALSE) {
set.seed(621)
indices <- createDataPartition(df$go, p = 0.8, list = FALSE)
x_train <- df[indices, -length(df)]
x_test <- df[-indices, -length(df)]
y_train <- df[indices, length(df)]
y_test <- df[-indices, length(df)]
tree <- rpart(y_train~.,
cbind(x_train, y_train),
method = "class")
yp_train <- predict(tree, newdata = x_train, type = "class")
yp_test <- predict(tree, newdata = x_test, type = "class")
confusion_matrix <- table(y_train, yp_train)
if(metrics){
print(confusionMatrix(confusion_matrix, positive = "1"))
}
accuracy <- round(confusionMatrix(confusion_matrix)$overall[1], 3)
fancyRpartPlot(tree,
caption = caption)
return(tree)
}
# Only using readily available information (field position, time left, score, etc.)
df1 <- df[,c(2, 3, 4, 5, 13, 14)]
tree <- make_tree(df1)
write.csv(df, "dt.csv")
load("data/clean_data.Rdata")
# Chunk 1: setup
library(tidyverse)
library(plotly)
library(reticulate)
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2: clean_data
load("data/clean_data.Rdata")
fourth_by_coach <- fourth_decisions %>%
group_by(coach) %>%
summarize(should_go = mean(should_go),
shouldnt_go = mean(shouldnt_go)) %>%
ungroup()
head(fourth_by_coach)
# Chunk 3: initial_viz
plot_ly(data = fourth_by_coach, x = ~should_go, y = ~shouldnt_go, type = "scatter", mode = "markers")
# Chunk 4: to_csv
write_csv(fourth_by_coach, file = "data/fourth_by_coach.csv")
# Chunk 5: imports
import pandas as pd
reticulate::repl_python()
