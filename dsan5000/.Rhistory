import praw
import config
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit(
client_id = "29BtHHkcVmVjeZfAU5Mfbw",
client_secret = "m8eoqej8ylk3LLG-n6TE1irUHOtxGw",
user_agent = "TNS621"
)
import praw
import config
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit(
client_id = config.client_id,
client_secret = config.client_secret,
user_agent = config.user_agent
)
subreddit = reddit.subreddit("nfl")
query = "4th down"
top_posts = subreddit.search(query, limit=100)
corpus = []
urls = []
for post in top_posts:
corpus.append(post.title)
urls.append(post.permalink)
vectorizer=CountVectorizer()
Xs = vectorizer.fit_transform(corpus)
col_names=vectorizer.get_feature_names_out()
subreddit = reddit.subreddit("nfl")
query = "4th down"
top_posts = subreddit.search(query, limit=100)
corpus = []
urls = []
for post in top_posts:
corpus.append(post.title)
for post in top_posts:
urls.append(post.permalink)
vectorizer=CountVectorizer()
Xs = vectorizer.fit_transform(corpus)
subreddit = reddit.subreddit("nfl")
query = "4th down"
top_posts = subreddit.search(query, limit=100)
corpus = []
urls = []
for post in top_posts:
urls.append(post.permalink)
vectorizer=CountVectorizer()
Xs = vectorizer.fit_transform(corpus)
col_names=vectorizer.get_feature_names_out()
import praw
import config
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit(
client_id = config.client_id,
client_secret = config.client_secret,
user_agent = config.user_agent
)
subreddit = reddit.subreddit("nfl")
query = "4th down"
top_posts = subreddit.search(query, limit=100)
corpus = []
urls = []
for post in top_posts:
urls.append(post.permalink)
vectorizer=CountVectorizer()
Xs = vectorizer.fit_transform(corpus)
col_names=vectorizer.get_feature_names_out()
config.client_id
config.client_secret
config.user_agent
client_secret = m8eoqej8ylk3LLG-n6TE1irUHOtxGw
client_id = 29BtHHkcVmVjeZfAU5Mfbw
client_secret = m8eoqej8ylk3LLG-n6TE1irUHOtxGw
user_agent = TNS621
import praw
import config
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit(
client_id = config.client_id,
client_secret = config.client_secret,
user_agent = config.user_agent
)
config.client_id
subreddit = reddit.subreddit("nfl")
query = "4th down"
top_posts = subreddit.search(query, limit=100)
corpus = []
urls = []
for post in top_posts:
urls.append(post.permalink)
vectorizer=CountVectorizer()
Xs = vectorizer.fit_transform(corpus)
col_names=vectorizer.get_feature_names_out()
(config.client_id)
config_user.id
config.user_agent
subreddit = reddit.subreddit("nfl")
query = "4th down"
top_posts = subreddit.search(query, limit=100)
corpus = []
urls = []
for post in top_posts:
urls.append(post.permalink)
vectorizer=CountVectorizer()
Xs = vectorizer.fit_transform(corpus)
col_names=vectorizer.get_feature_names_out()
import praw
import config
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit(
client_id = 29BtHHkcVmVjeZfAU5Mfbw,
client_secret = config.client_secret,
user_agent = TNS621
)
import praw
import config
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit(
client_id = "29BtHHkcVmVjeZfAU5Mfbw",
client_secret = config.client_secret,
user_agent = "TNS621"
)
config.client_secret
client_secret = m8eoqej8ylk3LLG-n6TE1irUHOtxGw
config.user_agent
import config
config.client_id
import config.py
import config
config.client_id
user_agent = TNS622
import config
config.user_agent
import config as c
c.user_agent
user_agent = TNS622
import praw
import config as c
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
c.user_agent
reddit = praw.Reddit("NFL")
)
import praw
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit("NFL")
import praw
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit("NFL")
os.getcwd()
os.getcwdb()
os.getcwd()
os.getcwd()
import os
os.getcwd()
import os
import praw
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
reddit = praw.Reddit("bot1")
os.getcwd()
reticulate::repl_python()
library(nflverse)
library(tidyverse)
library(ggplot2)
library(grid)
library(reticulate)
library(kableExtra)
use_condaenv("r-env")
options(scipen = 999)
reticulate::repl_python()
library(nflverse)
library(tidyverse)
library(ggplot2)
library(grid)
library(reticulate)
library(kableExtra)
use_condaenv("r-env")
options(scipen = 999)
reticulate::repl_python()
