import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.metrics import f1_score, accuracy_score
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from scipy.stats import zscore
import matplotlib.pyplot as plt
pd.set_option('display.float_format', '{:.3f}'.format)
rng = np.random.default_rng(621)
df = pd.read_csv("df.csv")
belichick = df[df['coach'] == 'Bill Belichick']
belichick = belichick.drop(columns =['coach', 'punt_wp'])
belichick['random_guess'] = rng.choice([0,1], len(belichick))
f1_random = f1_score(belichick['go'], belichick['random_guess'])
accuracy_random = accuracy_score(belichick['go'], belichick['random_guess'])
metrics = pd.DataFrame({"Metric" : ["F1 Score", "Accuracy Score"],
"Random Guessing" : [f1_random, accuracy_random]})
metrics
feature_matrix = belichick.drop(columns = ['go', 'random_guess'])
label_vec = belichick[['go']]
X_train, X_test, y_train, y_test = train_test_split(feature_matrix, label_vec, test_size=0.2, random_state=621)
model = GaussianNB()
model.fit(X_train, np.ravel(y_train))
test_predictions = model.predict(X_test)
f1_gaussianNB = f1_score(y_true = y_test, y_pred = test_predictions)
accuracy_gaussianNB = accuracy_score(y_true = y_test, y_pred = test_predictions)
metrics["GaussianNB"] = [f1_gaussianNB, accuracy_gaussianNB]
metrics
def merit(x,y,correlation="pearson"):
# x=matrix of features
# y=matrix (or vector) of targets
# correlation="pearson" or "spearman"
k = len(x)
feature = pd.DataFrame(x)
target = pd.DataFrame(y)
f_corr = feature.corr(method=correlation)
if(correlation == "pearson"):
f_t_corr = np.corrcoef(feature, target, rowvar=False)
else:
f_t_corr =  feature.apply(lambda col: col.corr(target, method = "spearman"))
rho_xx = f_t_corr.mean()
mask = np.triu(np.ones_like(f_corr), k=1)
rho_xy = f_corr[pd.DataFrame(mask) == 1].mean().mean()
return k*np.absolute(rho_xy)/(np.sqrt(k+k*(k+1)*np.absolute(rho_xx)))
x = feature_matrix.to_numpy()
y = label_vec.to_numpy()
def explore_data(x,y,iplot=True):
#PRINT SHAPE
print(x.shape)
print(y.shape)
#COMPUTE MERIT
print("merit =",merit(x,y,correlation="spearman"));
print("merit =",merit(x,y,correlation="pearson"))
#PLOT
if (iplot):
sns.pairplot(pd.DataFrame(np.hstack((x,y.reshape(y.shape[0],1)))))
plt.show()
# TEST YOUR CODE ABOVE
explore_data(x,y, iplot = False)
import itertools
def maximize_CFS(x,y):
k = x.shape[1]
max_merit = 0
list1 = [*range(0, k)]; #print(list1)
for L in range(2, len(list1) + 1):
for subset in itertools.combinations(list1, L):
m = merit(x[: ,subset], y)
if(m > max_merit):
max_merit = m
optimal_subset = subset
print("found new max: ", max_merit, "optimal features = ", list(subset))
return(x[:, optimal_subset])
x_opt=maximize_CFS(x,y)
explore_data(x_opt, y, iplot = False)
features_opt = pd.DataFrame(x_opt, columns = feature_matrix.columns[[3,11]])
def train_coach_model(coach):
coach_df = df[df['coach'] == coach]
# coach_df = coach_df[['yardline_100', 'miss_fg_wp', 'go']]
coach_df = coach_df.drop(columns = ['punt_wp', 'game_half'])
feature_matrix = coach_df.drop(columns = ['go', 'coach'])
feature_matrix = feature_matrix.apply(zscore)
label_vec = coach_df[['go']]
X_train, X_test, y_train, y_test = train_test_split(feature_matrix, label_vec, test_size=0.2, random_state=621)
model = GaussianNB()
model.fit(X_train, np.ravel(y_train))
test_predictions = model.predict(X_test)
f1_gaussianNB = f1_score(y_true = y_test, y_pred = test_predictions)
accuracy_gaussianNB = accuracy_score(y_true = y_test, y_pred = test_predictions)
metrics[coach] = [f1_gaussianNB, accuracy_gaussianNB]
compare_coaches[coach] = abs(model.theta_[1] - model.theta_[0])
return model
compare_coaches = pd.DataFrame({"Feature":feature_matrix.columns.to_list()})
# compare_coaches = pd.DataFrame({"Feature":features_opt.columns.to_list()})
staley_model = train_coach_model("Brandon Staley")
compare_coaches = pd.DataFrame({"Feature":feature_matrix.columns.to_list()})
staley_model = train_coach_model("Brandon Staley")
compare_coaches["Brandon Staley"]
compare_coaches
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
height_turnover_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
height_turnover_corr
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
time_yardline_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
time_yardline_corr
time_go_corr = spearmanr(included_vars_df['half_seconds_remaining'], label_vec).statistic
time_go_corr
yardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic
yardline_go_corr
k = 2
# since we only have two features there is only one correlation value, so this mean is just the one value
mean_xx_corr = time_yardline_corr
# mean_xy_corr is the mean of the two feature/label correlations from above
mean_xy_corr = np.mean([time_go_corr, yardline_go_corr])
print("Number of Features: {k}")
print(f"Number of Features: {k}")
meric_score_numer = k * np.absolute(mean_xy_corr)
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
time_yardline_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
time_yardline_corr
time_go_corr = spearmanr(included_vars_df['half_seconds_remaining'], label_vec).statistic
time_go_corr
yardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic
yardline_go_corr
k = 2
# since we only have two features there is only one correlation value, so this mean is just the one value
mean_xx_corr = time_yardline_corr #r_{xx}
# mean_xy_corr is the mean of the two feature/label correlations from above
mean_xy_corr = np.mean([time_go_corr, yardline_go_corr]) #r_{xy}
print(f"Number of Features: {k}")
meric_score_numer = k * np.absolute(mean_xy_corr)
merit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))
merit_score_s2 = merit_score_numer / merit_score_denom
print(f"Merit score: {merit_score_s2}")
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
time_yardline_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
time_yardline_corr
time_go_corr = spearmanr(included_vars_df['half_seconds_remaining'], label_vec).statistic
time_go_corr
yardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic
yardline_go_corr
k = 2
# since we only have two features there is only one correlation value, so this mean is just the one value
mean_xx_corr = time_yardline_corr #r_{xx}
# mean_xy_corr is the mean of the two feature/label correlations from above
mean_xy_corr = np.mean([time_go_corr, yardline_go_corr]) #r_{xy}
print(f"Number of Features: {k}")
meric_score_numer = k * np.absolute(mean_xy_corr)
merit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))
merit_score_s2 = merit_score_numer / merit_score_denom
print(f"Merit score: {merit_score_s2}")
print(f"Merit score: {merit_score_s2}")
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
time_yardline_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
time_yardline_corr
time_go_corr = spearmanr(included_vars_df['half_seconds_remaining'], label_vec).statistic
time_go_corr
yardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic
yardline_go_corr
k = 2
# since we only have two features there is only one correlation value, so this mean is just the one value
mean_xx_corr = time_yardline_corr #r_{xx}
# mean_xy_corr is the mean of the two feature/label correlations from above
mean_xy_corr = np.mean([time_go_corr, yardline_go_corr]) #r_{xy}
print(f"Number of Features: {k}")
meric_score_numer = k * np.absolute(mean_xy_corr)
merit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))
merit_score_s2 = merit_score_numer / merit_score_denom
print(f"Merit score: {merit_score_s2}")
merit_score_s2 = merit_score_numer / merit_score_denom
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
time_yardline_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
time_yardline_corr
time_go_corr = spearmanr(included_vars_df['half_seconds_remaining'], label_vec).statistic
time_go_corr
yardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic
yardline_go_corr
k = 2
# since we only have two features there is only one correlation value, so this mean is just the one value
mean_xx_corr = time_yardline_corr #r_{xx}
# mean_xy_corr is the mean of the two feature/label correlations from above
mean_xy_corr = np.mean([time_go_corr, yardline_go_corr]) #r_{xy}
print(f"Number of Features: {k}")
meric_score_numer = k * np.absolute(mean_xy_corr)
merit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))
merit_score_s2 = merit_score_numer / merit_score_denom
print(f"Merit score: {merit_score_s2}")
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
time_yardline_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
time_yardline_corr
time_go_corr = spearmanr(included_vars_df['half_seconds_remaining'], label_vec).statistic
time_go_corr
yardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic
yardline_go_corr
k = 2
# since we only have two features there is only one correlation value, so this mean is just the one value
mean_xx_corr = time_yardline_corr #r_{xx}
# mean_xy_corr is the mean of the two feature/label correlations from above
mean_xy_corr = np.mean([time_go_corr, yardline_go_corr]) #r_{xy}
print(f"Number of Features: {k}")
meric_score_numer = k * np.absolute(mean_xy_corr)
merit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))
merit_score_s2 = merit_score_numer / merit_score_denom
print(f"Merit score: {merit_score_s2}")
print(f"Merit score: {merit_score_s2}")
print(f"Merit score: {merit_score_s2}")
print(f"Merit score: {merit_score_s2}")
print(f"Merit score: {merit_score_s2}")
merit_score_s2
compare_coaches = pd.DataFrame({"Feature":feature_matrix.columns.to_list()})
staley_model = train_coach_model("Brandon Staley")
belichick_model = train_coach_model("Bill Belichick")
rivera_model = train_coach_model("Ron Rivera")
stefanski_model = train_coach_model("Kevin Stefanski")
compare_coaches = compare_coaches.T.iloc[1:]
compare_coaches.rename(columns = dict(zip(compare_coaches.columns, feature_matrix.columns.to_list())), inplace = True)
compare_coaches.style.set_table_styles([{'selector': '', 'props': [('border', '2px solid black')]}])
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
time_yardline_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
time_yardline_corr
time_go_corr = spearmanr(included_vars_df['half_seconds_remaining'], label_vec).statistic
time_go_corr
yardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic
yardline_go_corr
k = 2
# since we only have two features there is only one correlation value, so this mean is just the one value
mean_xx_corr = time_yardline_corr #r_{xx}
# mean_xy_corr is the mean of the two feature/label correlations from above
mean_xy_corr = np.mean([time_go_corr, yardline_go_corr]) #r_{xy}
print(f"Number of Features: {k}")
meric_score_numer = k * np.absolute(mean_xy_corr)
merit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))
merit_score_s2 = merit_score_numer / merit_score_denom
print(f"Merit score: {merit_score_s2}")
print("test")
from scipy.stats import spearmanr
#compute base merit score s_2
included_vars_s2 = ['half_seconds_remaining','yardline_100']
included_vars_df = feature_matrix[included_vars_s2].copy()
time_yardline_corr = spearmanr(included_vars_df['half_seconds_remaining'],
included_vars_df['yardline_100']).statistic
time_yardline_corr
time_go_corr = spearmanr(included_vars_df['half_seconds_remaining'], label_vec).statistic
time_go_corr
yardline_go_corr = spearmanr(included_vars_df['yardline_100'], label_vec).statistic
yardline_go_corr
k = 2
# since we only have two features there is only one correlation value, so this mean is just the one value
mean_xx_corr = time_yardline_corr #r_{xx}
# mean_xy_corr is the mean of the two feature/label correlations from above
mean_xy_corr = np.mean([time_go_corr, yardline_go_corr]) #r_{xy}
print(f"Number of Features: {k}")
meric_score_numer = k * np.absolute(mean_xy_corr)
merit_score_denom = np.sqrt(k + k * (k + 1) * np.absolute(mean_xx_corr))
merit_score_s2 = merit_score_numer / merit_score_denom
print("test")
print(f"Merit score: {merit_score_s2}")
print(merit_score_2)
View(merit_score_denom)
merit_score_s2 = merit_score_numer / merit_score_denom
print(f"Merit score: {merit_score_s2}")
reticulate::repl_python()
feature_matrix_s2 = feature_matrix[included_vars_s2].copy()
feature_matrix_s2 = feature_matrix[included_vars_sp2].copy()
reticulate::repl_python()
