{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Data Cleaning\n",
        "bibliography: reference.bib\n",
        "editor_options:\n",
        "  chunk_output_type: inline\n",
        "---"
      ],
      "id": "20ffa20b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data\n",
        "\n",
        "Data to evaluate NFL decision making was gathered by using the nflreadr package [@nflverse]. The creators of this package provide detailed instructions and examples on how to use and clean this data, which can be found at their website [here](https://nflreadr.nflverse.com/).\n",
        "\n",
        "# Cleaning Process\n",
        "\n",
        "## 4th Down Data\n",
        "\n",
        "\n",
        "```{r setup, include = FALSE}\n",
        "library(nflverse)\n",
        "library(tidyverse)\n",
        "library(ggplot2)\n",
        "library(grid)\n",
        "options(scipen = 999)\n",
        "knitr::opts_chunk$set(warning = FALSE, message = FALSE) \n",
        "```\n",
        "\n",
        "```{r load_data}\n",
        "raw_data <- load_4th_pbp(2022)\n",
        "```\n",
        "\n",
        "```{r head, message = FALSE}\n",
        "head(raw_data)\n",
        "```\n",
        "\n",
        "\n",
        "There are a large number of columns in this data, we do not need all 383. The purpose of this data is to help determine how coaches today approach 4th down, a basic yet essential decision in the NFL. To do this we only need to look at these columns:\n",
        "\n",
        "\n",
        "```{r, message = FALSE}\n",
        "fourth_downs <- raw_data %>%\n",
        "    filter(!is.na(go_boost) & !is.na(go)) %>%\n",
        "    select(home_coach, away_coach, posteam_type, ydstogo, yardline_100, posteam, go_boost, go, epa)\n",
        "\n",
        "head(fourth_downs)\n",
        "```\n",
        "\n",
        "\n",
        "Each unit in this table is one 4th down decision. The variables include:\n",
        "\n",
        "```{r}\n",
        "#names <- data.frame(names(fourth_downs))\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "## Text Data\n",
        "\n",
        "2.  Have Python code that cleans text data and includes a label (from corpus or csv or both) and you MUST use CountVectorizer.\n"
      ],
      "id": "3783e3f9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"hello world\")"
      ],
      "id": "3f545195",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(Optional but recommended) Have R code that cleans text data from a corpus for your project. (Optional but recommended) Have Python code that cleans record data for your project.\n",
        "\n",
        "Host your cleaning codes and data in the GitHub repository.\n",
        "\n",
        "Get your data into a cleaner state that will enable you to further (and later) prepare it for modeling."
      ],
      "id": "62bcbc3c"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}